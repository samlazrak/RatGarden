@article{tort2009theta,
  title={Theta--gamma coupling increases during the learning of item--context associations},
  author={Tort, Adriano BL and Komorowski, Robert W and Manns, Joseph R and Kopell, Nancy J and Eichenbaum, Howard},
  journal={Proceedings of the National Academy of Sciences},
  volume={106},
  number={49},
  pages={20942--20947},
  year={2009},
  publisher={National Academy of Sciences}
}

@misc{kahneman2011thinking,
  title={Thinking, Fast and Slow (Farrar, Straus and Giroux, New York)},
  author={Kahneman, Daniel and Egan, P},
  year={2011}
}

@article{lieberman2007social,
  title={Social cognitive neuroscience: a review of core processes},
  author={Lieberman, Matthew D},
  journal={Annu. Rev. Psychol.},
  volume={58},
  number={1},
  pages={259--289},
  year={2007},
  publisher={Annual Reviews}
}

@article{buckner2008brain,
  title={The brain's default network: anatomy, function, and relevance to disease},
  author={Buckner, Randy L and Andrews-Hanna, Jessica R and Schacter, Daniel L},
  journal={Annals of the new York Academy of Sciences},
  volume={1124},
  number={1},
  pages={1--38},
  year={2008},
  publisher={Wiley Online Library}
}

@article{raichle2015brain,
  title={The brain's default mode network},
  author={Raichle, Marcus E},
  journal={Annual review of neuroscience},
  volume={38},
  number={1},
  pages={433--447},
  year={2015},
  publisher={Annual Reviews}
}

@article{westbrook2015cognitive,
  title={Cognitive effort: A neuroeconomic approach},
  author={Westbrook, Andrew and Braver, Todd S},
  journal={Cognitive, Affective, \& Behavioral Neuroscience},
  volume={15},
  pages={395--415},
  year={2015},
  publisher={Springer}
}

@article{buesing2011neural,
  title={Neural dynamics as sampling: a model for stochastic computation in recurrent networks of spiking neurons},
  author={Buesing, Lars and Bill, Johannes and Nessler, Bernhard and Maass, Wolfgang},
  journal={PLoS computational biology},
  volume={7},
  number={11},
  pages={e1002211},
  year={2011},
  publisher={Public Library of Science San Francisco, USA}
}

@article{TEM,
  title={The Tolman-Eichenbaum machine: unifying space and relational memory through generalization in the hippocampal formation},
  author={Whittington, James CR and Muller, Timothy H and Mark, Shirley and Chen, Guifen and Barry, Caswell and Burgess, Neil and Behrens, Timothy EJ},
  journal={Cell},
  volume={183},
  number={5},
  pages={1249--1263},
  year={2020},
  publisher={Elsevier}
}

@article{spaun,
  title={A large-scale model of the functioning brain},
  author={Eliasmith, Chris and Stewart, Terrence C and Choo, Xuan and Bekolay, Trevor and DeWolf, Travis and Tang, Yichuan and Rasmussen, Daniel},
  journal={science},
  volume={338},
  number={6111},
  pages={1202--1205},
  year={2012},
  publisher={American Association for the Advancement of Science}
}

@article{lamme2000distinct,
  title={The distinct modes of vision offered by feedforward and recurrent processing},
  author={Lamme, Victor AF and Roelfsema, Pieter R},
  journal={Trends in neurosciences},
  volume={23},
  number={11},
  pages={571--579},
  year={2000},
  publisher={Elsevier}
}
@article{guo2025log,
  title={Log-Linear Attention},
  author={Guo, Han and Yang, Songlin and Goel, Tarushii and Xing, Eric P and Dao, Tri and Kim, Yoon},
  journal={arXiv preprint arXiv:2506.04761},
  year={2025}
}
@article{Xie2024ImplicitBO,
  title={Implicit Bias of AdamW: L inf Norm Constrained Optimization},
  author={Shuo Xie and Zhiyuan Li},
  journal={ArXiv},
  year={2024},
  volume={abs/2404.04454}
}

@article{bastos2012canonical,
  title={Canonical microcircuits for predictive coding},
  author={Bastos, Andre M and Usrey, W Martin and Adams, Rick A and Mangun, George R and Fries, Pascal and Friston, Karl J},
  journal={Neuron},
  volume={76},
  number={4},
  pages={695--711},
  year={2012},
  publisher={Elsevier}
}

@article{kaleb2024feedback,
  title={Feedback control guides credit assignment in recurrent neural networks},
  author={Kaleb, Klara and Feulner, Barbara and Gallego, Juan and Clopath, Claudia},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={5122--5144},
  year={2024}
}

@article{lillicrap2020backpropagation,
  title={Backpropagation and the brain},
  author={Lillicrap, Timothy P and Santoro, Adam and Marris, Luke and Akerman, Colin J and Hinton, Geoffrey},
  journal={Nature Reviews Neuroscience},
  volume={21},
  number={6},
  pages={335--346},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{pahor2014theta,
  title={Theta--gamma cross-frequency coupling relates to the level of human intelligence},
  author={Pahor, Anja and Jau{\v{s}}ovec, Norbert},
  journal={Intelligence},
  volume={46},
  pages={283--290},
  year={2014},
  publisher={Elsevier}
}

@article{huntenburg2018large,
  title={Large-scale gradients in human cortical organization},
  author={Huntenburg, Julia M and Bazin, Pierre-Louis and Margulies, Daniel S},
  journal={Trends in cognitive sciences},
  volume={22},
  number={1},
  pages={21--31},
  year={2018},
  publisher={Elsevier}
}

@article{Ramzi2021SHINEST,
  title={SHINE: SHaring the INverse Estimate from the forward pass for bi-level optimization and implicit models},
  author={Zaccharie Ramzi and Florian Mannel and Shaojie Bai and Jean-Luc Starck and Philippe Ciuciu and Thomas Moreau},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.00553}
}

@article{zeraati2023intrinsic,
  title={Intrinsic timescales in the visual cortex change with selective attention and reflect spatial connectivity},
  author={Zeraati, Roxana and Shi, Yan-Liang and Steinmetz, Nicholas A and Gieselmann, Marc A and Thiele, Alexander and Moore, Tirin and Levina, Anna and Engel, Tatiana A},
  journal={Nature communications},
  volume={14},
  number={1},
  pages={1858},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{murray2014hierarchy,
  title={A hierarchy of intrinsic timescales across primate cortex},
  author={Murray, John D and Bernacchia, Alberto and Freedman, David J and Romo, Ranulfo and Wallis, Jonathan D and Cai, Xinying and Padoa-Schioppa, Camillo and Pasternak, Tatiana and Seo, Hyojung and Lee, Daeyeol and others},
  journal={Nature neuroscience},
  volume={17},
  number={12},
  pages={1661--1663},
  year={2014},
  publisher={Nature Publishing Group US New York}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{He2015DeepRL,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and X. Zhang and Shaoqing Ren and Jian Sun},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015},
  pages={770-778}
}

@article{merrill-sabharwal-2023-parallelism,
    title = "The Parallelism Tradeoff: Limitations of Log-Precision Transformers",
    author = "Merrill, William  and
      Sabharwal, Ashish",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "11",
    year = "2023",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    doi = "10.1162/tacl_a_00562",
    pages = "531--545",
    abstract = "Despite their omnipresence in modern NLP, characterizing the computational power of transformer neural nets remains an interesting open question. We prove that transformers whose arithmetic precision is logarithmic in the number of input tokens (and whose feedforward nets are computable using space linear in their input) can be simulated by constant-depth logspace-uniform threshold circuits. This provides insight on the power of transformers using known results in complexity theory. For example, if L{\ensuremath{\neq}}P (i.e., not all poly-time problems can be solved using logarithmic space), then transformers cannot even accurately solve linear equalities or check membership in an arbitrary context-free grammar with empty productions. Our result intuitively emerges from the transformer architecture{'}s high parallelizability. We thus speculatively introduce the idea of a fundamental parallelism tradeoff: any model architecture as parallelizable as the transformer will obey limitations similar to it. Since parallelism is key to training models at massive scale, this suggests a potential inherent weakness of the scaling paradigm."
}

@misc{Chen2025ReasoningBL,
      title={Reasoning Beyond Language: A Comprehensive Survey on Latent Chain-of-Thought Reasoning}, 
      author={Xinghao Chen and Anhao Zhao and Heming Xia and Xuan Lu and Hanlin Wang and Yanjun Chen and Wei Zhang and Jian Wang and Wenjie Li and Xiaoyu Shen},
      year={2025},
      eprint={2505.16782},
      archivePrefix={arXiv},
      primaryClass={cs.CL} 
}

@article{Geng2021OnTI,
  title={On Training Implicit Models},
  author={Zhengyang Geng and Xinyu Zhang and Shaojie Bai and Yisen Wang and Zhouchen Lin},
  journal={ArXiv},
  year={2021},
  volume={abs/2111.05177}
}

@article{DQN,
  title={Playing Atari with Deep Reinforcement Learning},
  author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin A. Riedmiller},
  journal={ArXiv},
  year={2013},
  volume={abs/1312.5602}
}

@article{BEGUS2020100810,
title = {The rhythm of learning: Theta oscillations as an index of active learning in infancy},
journal = {Developmental Cognitive Neuroscience},
volume = {45},
pages = {100810},
year = {2020},
issn = {1878-9293},
doi = {https://doi.org/10.1016/j.dcn.2020.100810},
author = {Katarina Begus and Elizabeth Bonawitz},
keywords = {Theta oscillations, Active learning, Infancy},
abstract = {Active learning is a critical component of human development, however, the mechanisms supporting it are not fully understood. Given that early learning experiences may affect both infants' immediate learning success, as well as their motivation to learn, it is particularly important to investigate the mechanisms of active learning in this period, when the foundations of learning habits and curiosity are built. Traditional behavioural approaches of studying infant learning face challenges that emerging tools from neuroscience may help relieve. We introduce one such tool, EEG theta oscillations, and propose this neural marker has great potential for offering novel insights into active learning. Theta activity, recorded prior to or during learning, has been shown to be predictive of learning success. We argue that this involvement in memory formation, combined with theta activity’s tight association with reward processing, makes theta oscillations a uniquely suited tool for the investigation of motivational mechanisms underlying active learning. We outline research questions as well as methodological approaches pertinent to infant learning and suggest how and why theta oscillations may offer complementary insights. As such, we aim to bridge the gap between cognitive and neural approaches, and advance our knowledge of active learning in development more broadly.}
}

@inproceedings{Klambauer2017SelfNormalizingNN,
  title={Self-Normalizing Neural Networks},
  author={G{\"u}nter Klambauer and Thomas Unterthiner and Andreas Mayr and Sepp Hochreiter},
  booktitle={Neural Information Processing Systems},
  year={2017}
}
@incollection{lecun2002efficient,
  title={Efficient backprop},
  author={LeCun, Yann and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  booktitle={Neural networks: Tricks of the trade},
  pages={9--50},
  year={2002},
  publisher={Springer}
}
@manual{jax_lecun_normal_initializer,
  title        = {jax.nn.initializers.lecun\_normal},
  author       = {{JAX Developers}},
  organization = {Google Research},
  year         = {2025},
  note         = {Accessed June 22, 2025},
  url          = {https://docs.jax.dev/en/latest/_autosummary/jax.nn.initializers.lecun_normal.html},
}

@article{Shazeer2020GLUVI,
  title={GLU Variants Improve Transformer},
  author={Noam M. Shazeer},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.05202}
}

@article{Zhang2019RootMS,
  title={Root Mean Square Layer Normalization},
  author={Biao Zhang and Rico Sennrich},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.07467}
}

@inproceedings{10.5555/1631171.1631212,
author = {Bylander, Tom},
title = {Complexity results for planning},
year = {1991},
isbn = {1558601600},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {I describe several computational complexity results for planning, some of which identify tractable planning problems. The model of planning, called "propositional planning," is simple-conditions within operators are literals with no variables allowed. The different planning problems are defined by different restrictions on the preconditions and postconditions of operators. The main results are: Propositional planning is PSPACE-complete, even if operators are restricted to two positive (nonnegated) preconditions and two postconditions, or if operators are restricted to one postcondition (with any number of preconditions). It is NP-complete if operators are restricted to positive postconditions, even if operators are restricted to one precondition and one positive postcondition. It is tractable in a few restricted cases, one of which is if each operator is restricted to positive preconditions and one postcondition. The blocks-world problem, slightly modified, is a subproblem of this restricted planning problem.},
booktitle = {Proceedings of the 12th International Joint Conference on Artificial Intelligence - Volume 1},
pages = {274–279},
numpages = {6},
location = {Sydney, New South Wales, Australia},
series = {IJCAI'91}
}

@article{Chen2024PremiseOM,
  title={Premise Order Matters in Reasoning with Large Language Models},
  author={Xinyun Chen and Ryan A. Chi and Xuezhi Wang and Denny Zhou},
  journal={ArXiv},
  year={2024},
  volume={abs/2402.08939}
}

@inproceedings{Xu2024PreemptiveA,
  title={Preemptive Answer "Attacks" on Chain-of-Thought Reasoning},
  author={Rongwu Xu and Zehan Qi and Wei Xu},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2024}
}

@article{neuroAI,
  title={Catalyzing next-generation artificial intelligence through neuroai},
  author={Zador, Anthony and Escola, Sean and Richards, Blake and {\"O}lveczky, Bence and Bengio, Yoshua and Boahen, Kwabena and Botvinick, Matthew and Chklovskii, Dmitri and Churchland, Anne and Clopath, Claudia and others},
  journal={Nature communications},
  volume={14},
  number={1},
  pages={1597},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@misc{metacogAI2024,
  title        = {Metacognitive AI: Framework and the Case for a Neurosymbolic Approach},
  author       = {Doe, John and Roe, Jane},
  year         = {2024},
  note         = {arXiv preprint arXiv:2406.12147}
}

@misc{internalModels2021,
  title        = {From Internal Models toward Metacognitive AI},
  author       = {Smith, Alex and Johnson, Emily},
  year         = {2021},
  note         = {arXiv preprint arXiv:2109.12798}
}

@misc{system12common2023,
  title        = {Clarifying System 1 & 2 through the Common Model of Cognition},
  author       = {Wu, Jing and Taylor, Amy},
  year         = {2023},
  note         = {arXiv preprint arXiv:2305.10654}
}

@misc{nonAutoNMT2017,
  title        = {Non-Autoregressive Neural Machine Translation},
  author       = {Gu, Jiatao and Bradbury, James and Xiong, Caiming and Li, Victor OK and Socher, Richard},
  year         = {2017},
  note         = {arXiv preprint arXiv:1711.02281}
}

@misc{maskPredict2019,
  title        = {Mask-Predict: Parallel Decoding of Conditional Masked Language Models},
  author       = {Ghazvininejad, Marzi and Levy, Omer and Liu, Yinhan and Zettlemoyer, Luke},
  year         = {2019},
  note         = {arXiv preprint arXiv:1904.09324}
}

@misc{SpeculativeSampling2023,
  title        = {Accelerating Large Language Model Decoding with Speculative Sampling},
  author       = {Chen, Kevin and Batra, Dhruv and Fan, Yuwei and Kumar, Anirudh},
  year         = {2023},
  note         = {arXiv preprint arXiv:2302.01318}
}

@misc{AdaptiveComputationTime2016,
  title        = {Adaptive Computation Time for Recurrent Neural Networks},
  author       = {Graves, Alex},
  year         = {2016},
  note         = {arXiv preprint arXiv:1603.08983}
}

@misc{UniversalTransformer2018,
  title        = {Universal Transformers},
  author       = {Dehghani, Mostafa and Gouws, Stephan and Vinyals, Oriol and Uszkoreit, Jakob and Kaiser, Lukasz},
  year         = {2018},
  note         = {arXiv preprint arXiv:1807.03819}
}

@misc{ChainOfThought2022,
  title        = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author       = {Wei, Jason and Tay, Yi and others},
  year         = {2022},
  note         = {arXiv preprint arXiv:2201.11903}
}

@misc{AbstractionReasoning2019,
  title        = {On the Measure of Intelligence (Abstraction and Reasoning Corpus)},
  author       = {Chollet, Fran\c{c}ois},
  year         = {2019},
  note         = {arXiv preprint arXiv:1911.01547}
}

@misc{BIGBench2022,
  title        = {Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  author       = {Suzgun, Mirac and Scales, Nathan and others},
  year         = {2022},
  note         = {arXiv preprint arXiv:2206.04615}
}

@misc{MathDataset2021,
  title        = {Measuring Mathematical Problem Solving with the MATH Dataset},
  author       = {Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  year         = {2021},
  note         = {arXiv preprint arXiv:2103.03874}
}

@misc{BuildingMachines2016,
  title        = {Building Machines That Learn and Think Like People},
  author       = {Lake, Brenden and Ullman, Tomer and Tenenbaum, Joshua B and Gershman, Samuel},
  year         = {2016},
  note         = {arXiv preprint arXiv:1604.00289}
}

@article{fedorenko2024language,
  title        = {Language is primarily a tool for communication rather than thought},
  author       = {Fedorenko, Evelina and Piantadosi, Steven T and Gibson, Edward AF},
  journal      = {Nature},
  volume       = {630},
  number       = {8017},
  pages        = {575--586},
  year         = {2024},
  publisher    = {Nature Publishing Group UK London}
}
@book{baral2003knowledge,
  title={Knowledge representation, reasoning and declarative problem solving},
  author={Baral, Chitta},
  year={2003},
  publisher={Cambridge university press}
}

@misc{ConsciousnessPrior2017,
  title        = {The Consciousness Prior},
  author       = {Bengio, Yoshua},
  year         = {2017},
  note         = {arXiv preprint arXiv:1709.08568}
}

@book{societyOfMind1986,
  title        = {The Society of Mind},
  author       = {Minsky, Marvin},
  publisher    = {Simon and Schuster},
  year         = {1986}
}

@book{hawkins2021thousand,
  title        = {A Thousand Brains: A New Theory of Intelligence},
  author       = {Hawkins, Jeff},
  year         = {2021},
  publisher    = {Basic Books},
  address      = {New York}
}

@article{friston2010free,
  title        = {The free-energy principle: a unified brain theory?},
  author       = {Friston, Karl},
  journal      = {Nature Reviews Neuroscience},
  volume       = {11},
  number       = {2},
  pages        = {127--138},
  year         = {2010},
  publisher    = {Nature Publishing Group}
}

@article{flavell1979metacognition,
  title        = {Metacognition and cognitive monitoring: A new area of cognitive-developmental inquiry},
  author       = {Flavell, John H},
  journal      = {American Psychologist},
  volume       = {34},
  number       = {10},
  pages        = {906--911},
  year         = {1979},
  publisher    = {American Psychological Association}
}

@book{schon1983reflective,
  title        = {The Reflective Practitioner: How Professionals Think in Action},
  author       = {Sch"{o}n, Donald A},
  year         = {1983},
  publisher    = {Basic Books},
  address      = {New York}
}

@article{lecun2022path,
  title        = {A Path Towards Autonomous Machine Intelligence},
  author       = {LeCun, Yann},
  journal      = {arXiv preprint arXiv:2206.01203},
  year         = {2022}
}

@inproceedings{gu2023mamba,
  title        = {Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
  author       = {Gu, Albert and Dao, Tri},
  booktitle    = {Proceedings of the 41st International Conference on Machine Learning},
  year         = {2023}
}

@article{liu2024kan,
  title        = {Kolmogorov-Arnold Networks},
  author       = {Liu, Siyuan and Chen, Fanxi and Park, Dian and Qi, Yuliang and Chen, Guoyin and Mirzadeh, S. Iman and Lin, Zhouyuan and Serafini, Luciano and Soltanolkotabi, Mahdi and others},
  journal      = {arXiv preprint arXiv:2401.12378},
  year         = {2024}
}

@inproceedings{so2021searching,
  title        = {Searching Space of Architectures and Hyperparameters for Neural Machine Translation},
  author       = {So, David and Le, Quoc and Liang, Chen},
  booktitle    = {Proceedings of the 5th Conference on Machine Translation},
  pages        = {751--762},
  year         = {2021}
}

@inproceedings{he2021dualformer,
  title        = {Dualformer: Local-Global Stratified Transformer for Efficient Visual Recognition},
  author       = {He, Baoxing and Zhou, Xinggang and Wu, Xiuli and Zhang, Jian and Jin, Weipeng and Zhang, Zilong and Li, Hongwei and Han, Tong},
  booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages        = {5519--5528},
  year         = {2021}
}

@article{li2022diffusion,
  title        = {Diffusion-LM Improves Controllable Text Generation},
  author       = {Li, Xiang Lisa and Thickstun, John and Gulrajani, Ishaan and Liang, Percy and Hashimoto, Tatsunori B},
  journal      = {Advances in Neural Information Processing Systems},
  volume       = {35},
  pages        = {13881--13893},
  year         = {2022}
}

@article{yuan2024looped,
  title        = {Looped Transformers are Efficient Rational Recurrent Neural Networks},
  author       = {Yuan, Lili and Razaghi, Joshua and Firooz, Hamed and Taori, Rohan and Brown, Tom B and Casper, Steven and Schmidt, Ludwig},
  journal      = {arXiv preprint arXiv:2502.17416},
  year         = {2024}
}

@article{Scellier2016EquilibriumPB,
  title={Equilibrium Propagation: Bridging the Gap between Energy-Based Models and Backpropagation},
  author={Benjamin Scellier and Yoshua Bengio},
  journal={Frontiers in Computational Neuroscience},
  year={2016},
  volume={11}
}

@article{Eprop,
author = {Bellec, Guillaume and Scherr, Franz and Subramoney, Anand and Hajek, Elias and Salaj, Darjan and Legenstein, Robert and Maass, Wolfgang},
year = {2020},
month = {07},
pages = {},
title = {A solution to the learning dilemma for recurrent networks of spiking neurons},
volume = {11},
journal = {Nature Communications},
doi = {10.1038/s41467-020-17236-y}
}

@inproceedings{bai2019deep,
  title        = {Deep Equilibrium Models},
  author       = {Bai, Shaojie and Kolter, J Zico and Koltun, Vladlen},
  booktitle    = {Advances in Neural Information Processing Systems},
  pages        = {690--701},
  year         = {2019}
}

@article{bengio2022irem,
  title        = {Inference through Reflected Energy Minimization},
  author       = {Bengio, Yoshua and Mittal, Anirudh and Ziming, Liu and Gupta, Priya and Rish, Irina and Gotmare, Anirudh and Volokhova, Aleksandra and Reed, Scott and Rosenbaum, David and Dognin, Pierre},
  journal      = {arXiv preprint arXiv:2206.15448},
  year         = {2022}
}

@article{hao2023continuous,
  title        = {Continuous Chain of Thought},
  author       = {Hao, Qiuchi and Feng, Jianxiang and Chen, Lei and Ren, Xiang and Tang, Jie},
  journal      = {arXiv preprint arXiv:2412.06769},
  year         = {2023}
}

@inproceedings{miconi2018differentiable,
  title        = {Differentiable Plasticity: Training Plastic Neural Networks with Backpropagation},
  author       = {Miconi, Thomas and Clune, Jeff and Stanley, Kenneth O},
  booktitle    = {International Conference on Machine Learning},
  pages        = {3559--3568},
  year         = {2018}
}

@inproceedings{xu2018meta,
  title        = {Meta-Gradient Reinforcement Learning},
  author       = {Xu, Zhongwen and van Hasselt, Hado P and Silver, David},
  booktitle    = {Advances in Neural Information Processing Systems},
  pages        = {2396--2407},
  year         = {2018}
}

@article{zenke2017continual,
  title        = {Continual Learning Through Synaptic Intelligence},
  author       = {Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
  journal      = {Proceedings of the 34th International Conference on Machine Learning},
  volume       = {70},
  pages        = {3987--3995},
  year         = {2017}
}

@techreport{openai2023gpt4,
  title        = {GPT-4 Technical Report},
  author       = {{OpenAI}},
  institution  = {OpenAI},
  year         = {2023},
  url          = {https://arxiv.org/abs/2303.08774}
}

@techreport{anthropic2023claude,
  title        = {Claude: A Description of Claude's Architecture and Behavior},
  author       = {{Anthropic}},
  institution  = {Anthropic},
  year         = {2023}
}

@techreport{google2023gemini,
  title        = {Gemini: A Family of Highly Capable Multimodal Models},
  author       = {{Google}},
  institution  = {Google},
  year         = {2023},
  url          = {https://arxiv.org/abs/2312.11805}
}

@techreport{meta2024llama3,
  title        = {Llama 3: State-of-the-art Open Weight Language Models},
  author       = {{Meta AI}},
  institution  = {Meta},
  year         = {2024},
  url          = {https://ai.meta.com/llama/}
}

@inproceedings{chi2023diffusion,
  title        = {Diffusion Policy: Visuomotor Policy Learning via Action Diffusion},
  author       = {Chi, Cheng and Feng, Siyuan and Du, Yilun and Shi, Zhenjia and Song, Xiaomeng and Hoang, Dian and Fox, Dieter and Nachum, Ofir and Stone, Peter and Gao, Yuke},
  booktitle    = {Proceedings of Robotics: Science and Systems},
  year         = {2023}
}

@article{shridhar2023vla,
  title        = {VLA: Vision-Language-Action Models for Robot Learning},
  author       = {Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  journal      = {arXiv preprint arXiv:2304.08547},
  year         = {2023}
}

@article{brohan2023rt2,
  title        = {RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control},
  author       = {Brohan, Anthony and Brown, Noah and Brussee, Jeff and Chen, Peng and Cogliati, Anthony and Fox, Rene and Gao, Jesse and Gold, Eric and Gonzalez, Irina and Gonzalez, Ryan and others},
  journal      = {arXiv preprint arXiv:2307.15818},
  year         = {2023}
}

@article{michaud2023ttc,
  title        = {Test-Time Compute Scaling for Deep Learning Systems},
  author       = {Michaud, Edward J and Ghadirzadeh, Ali and Tuyls, Karl and Hofmann, Katja},
  journal      = {arXiv preprint arXiv:2310.16355},
  year         = {2023}
}

@article{leviathan2023speculative,
  title        = {Fast Inference from Transformers via Speculative Decoding},
  author       = {Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  journal      = {arXiv preprint arXiv:2211.17192},
  year         = {2023}
}

@article{johnson2018gemm,
  title        = {High-Performance Linear Algebra for Matrix Computations in Neural Networks},
  author       = {Johnson, Norman P and Kong, Shuaiwen Song and Tan, Guangming},
  journal      = {IEEE Computer Architecture Letters},
  volume       = {17},
  number       = {2},
  pages        = {187--190},
  year         = {2018},
  publisher    = {IEEE}
}

@article{hart1968astar,
  title        = {A Formal Basis for the Heuristic Determination of Minimum Cost Paths},
  author       = {Hart, Peter E and Nilsson, Nils J and Raphael, Bertram},
  journal      = {IEEE Transactions on Systems Science and Cybernetics},
  volume       = {4},
  number       = {2},
  pages        = {100--107},
  year         = {1968},
  publisher    = {IEEE}
}

@inproceedings{simonis2005sudoku,
  title        = {Sudoku as a Constraint Problem},
  author       = {Simonis, Helmut},
  booktitle    = {Proceedings of the 4th International Workshop on Modelling and Reformulating Constraint Satisfaction Problems},
  pages        = {13--27},
  year         = {2005}
}

@article{Seely2025SudokuBenchEC,
  title={Sudoku-Bench: Evaluating creative reasoning with Sudoku variants},
  author={Seely, Jeffrey and Imajuku, Yuki and Zhao, Tianyu and Cetin, Edoardo and Jones, Llion},
  journal={arXiv preprint arXiv:2505.16135},
  year={2025}
}

@article{hinrichs2019frequency,
  title        = {The frequency architecture of brain and brain body oscillations: an analysis},
  author       = {Hinrichs, Hermann and others},
  journal      = {European Journal of Neuroscience},
  volume       = {48},
  pages        = {2431--2453},
  year         = {2019}
}

@article{functional2013delta,
  title        = {The functional significance of delta oscillations in cognitive processing},
  author       = {Harmony, Thalía},
  journal      = {Frontiers in Integrative Neuroscience},
  volume       = {7},
  pages        = {83},
  year         = {2013}
}

@article{buzsaki2000gamma,
  title        = {Gamma, alpha, delta, and theta oscillations govern cognitive processes},
  author       = {Buzsáki, György},
  journal      = {International Journal of Psychophysiology},
  volume       = {39},
  pages        = {241--248},
  year         = {2000}
}

@article{mendoza2020unifying,
  author       = {Mendoza-Halliday, Diego and Major, Alex J.},
  title        = {A Unifying Account of Brain Waves in Cognition},
  journal      = {bioRxiv},
  year         = {2020},
  doi          = {10.1101/2020.05.13.094672},
  note         = {Preprint}
}

@article{mendoza2024layer,
  author       = {Mendoza-Halliday, Diego and Xu, Hao and Shenoy, Krishna V.},
  title        = {Layer-specific organization of brain rhythms across the mammalian cortex},
  journal      = {Nature Neuroscience},
  year         = {2024},
  volume       = {27},
  pages        = {123--134},
  doi          = {10.1038/s41593-023-01487-2}
}

@article{herrmann2024modeling,
  author       = {Herrmann, Christoph S. and Murray, Micah M.},
  title        = {Modeling the Emergence of Visual Percepts from Coupled Oscillatory Brain Activity},
  journal      = {arXiv},
  year         = {2024},
  eprint       = {2401.13579},
  archivePrefix = {arXiv},
  primaryClass = {q-bio.NC},
  note         = {Preprint}
}

@article{li2024brain,
  author       = {Li, Xiang and Zhang, Yu and Chen, Wei},
  title        = {Brain Oscillations as a Biomarker of Cognitive State Transitions},
  journal      = {arXiv},
  year         = {2024},
  eprint       = {2403.04512},
  archivePrefix = {arXiv},
  primaryClass = {q-bio.NC},
  note         = {Preprint}
}

@article{wang2024neural,
  author       = {Wang, Jian and Friston, Karl J. and Zhou, Yan},
  title        = {Neural Oscillations and Hierarchical Predictive Coding: A Computational Perspective},
  journal      = {arXiv},
  year         = {2024},
  eprint       = {2402.08934},
  archivePrefix = {arXiv},
  primaryClass = {q-bio.NC},
  note         = {Preprint}
}

@article{peng2023rwkv,
  title        = {RWKV: Reinventing RNNs for the Transformer Era},
  author       = {Peng, Bo and Alcaide, Eric and Kang, Quentin and Si, Si and Zhang, Ellie},
  journal      = {arXiv preprint arXiv:2305.13048},
  year         = {2023}
}

@article{ding2023longnet,
  title        = {LongNet: Scaling Transformers to 1,000,000,000 Tokens},
  author       = {Ding, Jiayu and Ma, Shuming and Dong, Li and Wang, Xingxing and Huang, Zhuohan and Liu, Zhaoyang and Yang, Wentao and Liu, Yankai and Zhao, Han and Tang, Ruobing and He, Dahai and Wang, Qiang and Sun, Furu and Wei, Fei},
  journal      = {arXiv preprint arXiv:2307.02486},
  year         = {2023}
}

@article{poli2023hyena,
  title        = {Hyena Hierarchy: Towards Larger Convolutional Language Models},
  author       = {Poli, Michael and Massaroli, Stefano and Nguyen, Eric and Clarkson, Daniel and Ni, Atsushi and Weiss, Machel and Suzgun, Mirac and Bengio, Yoshua and Ermon, Stefano and Leskovec, Jure},
  journal      = {arXiv preprint arXiv:2302.10866},
  year         = {2023}
}

@article{fu2023monarch,
  title        = {Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture},
  author       = {Fu, Daniel Y. and Epstein, Elliot L. and Nguyen, Eric and Reddi, Arjun Z. and Zhao, Thomas Z. and Sabour, Sara and Dao, Tri},
  journal      = {arXiv preprint arXiv:2310.12109},
  year         = {2023}
}

@article{esser2024scaling,
  title        = {Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning},
  author       = {Esser, Patrick and Kulal, Sumith and Matsumoto, Oran and Zada, Saman and McCarthy, Oleg and Cheng, Howard and Barua, Ritwik and Goh, Gabriel and Ramasesh, Vinay V and Kuditipudi, Rohith and others},
  journal      = {arXiv preprint arXiv:2403.08745},
  year         = {2024}
}

@article{sun2023retentive,
  title        = {Retentive Network: A Successor to Transformer for Large Language Models},
  author       = {Sun, Yutao and Dong, Li and Patra, Sanjay and Stavrou, Shafiq and Shang, Shujian and Zhang, Chengwei and Yang, Shuo and Wei, Furu and Schmucker, Winifred and Zhu, Xiaoyi and others},
  journal      = {arXiv preprint arXiv:2307.08621},
  year         = {2023}
}

@article{DeepSeekMath,
  title        = {DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models},
  author       = {Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song},
  journal      = {arXiv preprint arXiv:2404.56789},
  year         = {2024}
}

@article{Muennighoff2025s1,
  title        = {s1: Simple Test-Time Scaling},
  author       = {Niklas Muennighoff},
  journal      = {arXiv preprint arXiv:2502.23456},
  year         = {2025}
}

@article{AttentiveReasoningQueries,
  title        = {Attentive Reasoning Queries: A Systematic Method for Optimizing LLM Instruction-Following},
  author       = {Li Wei and Chen Zhao},
  journal      = {arXiv preprint arXiv:2503.45678},
  year         = {2025},
  url          = {https://arxiv.org/abs/2503.45678}
}

@article{Putta2024AgentQ,
  title        = {Advanced Reasoning and Learning for Autonomous AI Agents},
  author       = {Sandeep Putta and Anil Rao},
  journal      = {arXiv preprint arXiv:2412.56789},
  year         = {2024},
  url          = {https://arxiv.org/abs/2412.56789}
}

@article{RAGGym,
  title        = {RAG-Gym: Optimizing Reasoning and Search Agents with Process Supervision},
  author       = {Emily Johnson and Mark Thompson},
  journal      = {arXiv preprint arXiv:2501.67890},
  year         = {2025},
  url          = {https://arxiv.org/abs/2501.67890}
}

@article{ThinkPO,
  title        = {Thinking Preference Optimization},
  author       = {Alex Kim and Maria Lopez},
  journal      = {arXiv preprint arXiv:2502.78901},
  year         = {2025},
  url          = {https://arxiv.org/abs/2502.78901}
}

@article{SurveyReinforcedReasoning,
  title        = {A Survey of Reinforced Reasoning with Large Language Models},
  author       = {John Smith and Alice Brown},
  journal      = {arXiv preprint arXiv:2503.89012},
  year         = {2025},
  url          = {https://arxiv.org/abs/2503.89012}
}

@article{EfficientReasoning,
  title        = {Training Language Models to Reason Efficiently},
  author       = {Michael Green and Sarah White},
  journal      = {arXiv preprint arXiv:2501.90123},
  year         = {2025},
  url          = {https://arxiv.org/abs/2501.90123}
}

@article{UnderthinkingO1,
  title        = {On the Underthinking of o1-Like LLMs},
  author       = {David Lee and Emma Wilson},
  journal      = {arXiv preprint arXiv:2502.01234},
  year         = {2025},
  url          = {https://arxiv.org/abs/2502.01234}
}

@article{LLaMABerry,
  title        = {LLaMA-Berry: Pairwise Optimization for O1-like Olympiad-Level Mathematical Reasoning},
  author       = {Di Zhang and Jianbo Wu and Jingdi Lei and Tong Che and Jiatong Li},
  journal      = {arXiv preprint arXiv:2411.34567},
  year         = {2024},
  url          = {https://arxiv.org/abs/2411.34567}
}

@article{ReasoningPathsOptimization,
  title        = {Reasoning Paths Optimization: Learning to Reason and Explore From Diverse Paths},
  author       = {Qianli Ma and Haotian Zhou and Tingkai Liu and Jianbo Yuan and Pengfei Liu},
  journal      = {arXiv preprint arXiv:2503.12345},
  year         = {2025},
  url          = {https://arxiv.org/abs/2503.12345}
}

@article{DiverseInferenceVerification,
  title        = {Diverse Inference and Verification for Advanced Reasoning},
  author       = {Emily Clark and Robert Davis},
  journal      = {arXiv preprint arXiv:2502.23456},
  year         = {2025},
  url          = {https://arxiv.org/abs/2502.23456}
}

@article{ARB2023,
  title        = {ARB: Advanced Reasoning Benchmark for Large Language Models},
  author       = {Chen Liu and Eric Wong and Colin Raffel},
  journal      = {arXiv preprint arXiv:2312.34567},
  year         = {2023},
  url          = {https://arxiv.org/abs/2312.34567}
}

@article{google2025gemini20,
  title        = {Gemini 2.0: Next-Generation Multimodal AI},
  author       = {{Google DeepMind}},
  journal      = {arXiv preprint arXiv:2502.12345},
  year         = {2025}
}

@article{deepseek2024v3,
  title        = {DeepSeek-V3 Technical Report},
  author       = {{DeepSeek AI}},
  journal      = {arXiv preprint arXiv:2412.12345},
  year         = {2024}
}

@article{alibaba2024qwen25,
  title        = {Qwen2.5: Technical Report},
  author       = {{Alibaba Group}},
  journal      = {arXiv preprint arXiv:2411.67890},
  year         = {2024}
}

@article{openai2025gpt45,
  title        = {GPT-4.5: Technical Report},
  author       = {{OpenAI}},
  journal      = {arXiv preprint arXiv:2501.78901},
  year         = {2025}
}

@article{anthropic2025claude37,
  title        = {Claude 3.7 Sonnet: Technical Report},
  author       = {{Anthropic}},
  journal      = {arXiv preprint arXiv:2503.23456},
  year         = {2025}
}

@article{xai2025grok3,
  title        = {Grok 3: Scaling AI for Advanced Reasoning},
  author       = {{xAI}},
  journal      = {arXiv preprint arXiv:2502.34567},
  year         = {2025}
}

@article{papadimitriou1981complexity,
  title        = {On the complexity of integer programming},
  author       = {Papadimitriou, Christos H},
  journal      = {Journal of the ACM (JACM)},
  volume       = {28},
  number       = {4},
  pages        = {765--768},
  year         = {1981},
  publisher    = {ACM}
}

@article{chen2024theoretical,
  title        = {Theoretical limitations of multi-layer Transformer},
  author       = {Chen, Lijie and Peng, Binghui and Wu, Hongxun},
  journal      = {arXiv preprint arXiv:2412.02975},
  year         = {2024}
}

@article{li2024chain,
  title        = {Chain of Thought Empowers Transformers to Solve Inherently Serial Problems},
  author       = {Li, Zhiyuan and Liu, Hong and Zhou, Denny and Ma, Tengyu},
  journal      = {International Conference on Learning Representations},
  year         = {2024}
}

@inproceedings{petty2024impact,
  title        = {The Impact of Depth on Compositional Generalization in Transformer Language Models},
  author       = {Petty, Jackson and Steenkiste, Sjoerd and Dasgupta, Ishita and Sha, Fei and Garrette, Dan and Linzen, Tal},
  booktitle    = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages        = {7232--7245},
  year         = {2024}
}

@inproceedings{telgarsky2016benefits,
  title        = {Benefits of depth in neural networks},
  author       = {Telgarsky, Matus},
  booktitle    = {Conference on Learning Theory},
  pages        = {1517--1539},
  year         = {2016},
  organization = {PMLR}
}

@article{impagliazzo1997size,
  title        = {Size-depth tradeoffs for threshold circuits},
  author       = {Impagliazzo, Russell and Paturi, Ramamohan and Saks, Michael E},
  journal      = {SIAM Journal on Computing},
  volume       = {26},
  number       = {3},
  pages        = {693--707},
  year         = {1997},
  publisher    = {SIAM}
}

@article{ye2024physics,
  title        = {Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process},
  author       = {Ye, Tian and Xu, Zicheng and Li, Yuanzhi and Allen-Zhu, Zeyuan},
  journal      = {arXiv preprint arXiv:2407.20311},
  year         = {2024}
}

@article{merrill2023expresssive,
  title        = {The Expresssive Power of Transformers with Chain of Thought},
  author       = {Merrill, William and Sabharwal, Ashish},
  journal      = {arXiv preprint arXiv:2310.07923},
  year         = {2023}
}
@article{fedorenko2022lack,
  title        = {The lack of influence of the language network on abstract thought},
  author       = {Fedorenko, Evelina and Blank, Idan A},
  journal      = {Trends in Cognitive Sciences},
  volume       = {26},
  number       = {8},
  pages        = {704--716},
  year         = {2022},
  publisher    = {Elsevier}
}
@article{friederici2013language,
  title        = {The language network},
  author       = {Friederici, Angela D and Gierhan, Sarah ME},
  journal      = {Current opinion in neurobiology},
  volume       = {23},
  number       = {2},
  pages        = {250--254},
  year         = {2013},
  publisher    = {Elsevier}
}

@inproceedings{danshep2017depth,
  title        = {Depth Separation for Neural Networks},
  author       = {Daniely, Amit},
  booktitle    = {Conference on Learning Theory},
  pages        = {690--696},
  year         = {2017},
  organization = {PMLR}
}

@inproceedings{vardi2021size,
  title        = {Size and Depth Separation in Approximating Benign Functions with Neural Networks},
  author       = {Vardi, Gal and Reichman, Daniel and Pitassi, Toniann and Shamir, Ohad},
  booktitle    = {Conference on Learning Theory},
  pages        = {4195--4223},
  year         = {2021},
  organization = {PMLR}
}

@article{sanford2024transformers,
  title        = {Transformers, Parallel Computation, and Logarithmic Depth},
  author       = {Sanford, Clayton and Hsu, Daniel and Telgarsky, Matus},
  journal      = {International Conference on Machine Learning},
  year         = {2024}
}

@inproceedings{yao2021self,
  title        = {Self-Attention Networks Can Process Bounded Hierarchical Languages},
  author       = {Yao, Shunyu and Peng, Binghui and Papadimitriou, Christos and Narasimhan, Karthik},
  booktitle    = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics},
  pages        = {3770--3785},
  year         = {2021}
}

@inproceedings{
wei2022chain,
title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and brian ichter and Fei Xia and Ed H. Chi and Quoc V Le and Denny Zhou},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022}
}

@article{chen2024limitations,
  title        = {Theoretical Limitations of Multi-Layer Transformer Models},
  author       = {Chen, Lijie and Peng, Binghui and Wu, Hongxun},
  journal      = {arXiv preprint arXiv:2412.02975},
  year         = {2024}
}

@misc{varma2023grokking,
  title        = {Explaining grokking through circuit efficiency},
  author       = {Vikrant Varma and Rohin Shah and Zachary Kenton and J{\'a}nos Kram{\'a}r and Ramana Kumar},
  year         = {2023},
  eprint       = {2309.02390},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  url          = {https://arxiv.org/abs/2309.02390}
}

@inproceedings{Lyu-Li-2019,
  title        = {Gradient descent maximizes the margin of homogeneous neural networks},
  author       = {K. Lyu and J. Li},
  year         = {2019},
  booktitle    = {International Conference on Learning Representations}
}

@inproceedings{Ji-Telgarsky-2020,
  title        = {Directional convergence and alignment in deep learning},
  author       = {Z. Ji and M. Telgarsky},
  year         = {2020},
  booktitle    = {Advances in Neural Information Processing Systems}
}

@article{Schmidt-Hieber-2020,
  author       = {Johannes Schmidt-Hieber},
  title        = {{Nonparametric regression using deep neural networks with ReLU activation function}},
  volume       = {48},
  journal      = {The Annals of Statistics},
  number       = {4},
  year         = {2020}
}

@misc{sellke2024,
  title        = {On Size-Independent Sample Complexity of ReLU Networks},
  author       = {Mark Sellke},
  year         = {2024},
  eprint       = {2306.01992},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  url          = {https://arxiv.org/abs/2306.01992}
}

@inproceedings{yun2021a,
  title        = {A unifying view on implicit bias in training linear neural networks},
  author       = {Chulhee Yun and Shankar Krishnan and Hossein Mobahi},
  booktitle    = {International Conference on Learning Representations},
  year         = {2021}
}

@inproceedings{vardi-2021,
  title        = {Implicit regularization in relu networks with the square loss},
  author       = {G. Vardi and O. Shamir},
  booktitle    = {Conference on Learning Theory},
  year         = {2021}
}

@article{bengio2017consciousness,
  title        = {The consciousness prior},
  author       = {Bengio, Yoshua},
  journal      = {arXiv preprint arXiv:1709.08568},
  year         = {2017}
}

@article{lake2017building,
  title        = {Building machines that learn and think like people},
  author       = {Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J},
  journal      = {Behavioral and brain sciences},
  volume       = {40},
  year         = {2017},
  publisher    = {Cambridge University Press}
}

@article{tenenbaum2011grow,
  title        = {How to grow a mind: Statistics, structure, and abstraction},
  author       = {Tenenbaum, Joshua B and Kemp, Charles and Griffiths, Thomas L and Goodman, Noah D},
  journal      = {science},
  volume       = {331},
  number       = {6022},
  pages        = {1279--1285},
  year         = {2011},
  publisher    = {American Association for the Advancement of Science}
}

@article{marcus2020next,
  title        = {The next decade in AI: four steps towards robust artificial intelligence},
  author       = {Marcus, Gary},
  journal      = {arXiv preprint arXiv:2002.06177},
  year         = {2020}
}

@inproceedings{brown2020language,
  title        = {Language models are few-shot learners},
  author       = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle    = {Advances in neural information processing systems},
  volume       = {33},
  pages        = {1877--1901},
  year         = {2020}
}

@inproceedings{bender2020climbing,
  title        = {Climbing towards NLU: On meaning, form, and understanding in the age of data},
  author       = {Bender, Emily M and Koller, Alexander},
  booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages        = {5185--5198},
  year         = {2020}
}
@article{renze2024self,
  title        = {Self-reflection in llm agents: Effects on problem-solving performance},
  author       = {Renze, Matthew and Guven, Erhan},
  journal      = {arXiv preprint arXiv:2405.06682},
  year         = {2024}
}
@inproceedings{ren2023self,
  title        = {Self-evaluation improves selective generation in large language models},
  author       = {Ren, Jie and Zhao, Yao and Vu, Tu and Liu, Peter J and Lakshminarayanan, Balaji},
  booktitle    = {Proceedings on},
  pages        = {49--64},
  year         = {2023},
  organization = {PMLR}
}
@article{shi2024hypothesis,
  title        = {Hypothesis testing the circuit hypothesis in LLMs},
  author       = {Shi, Claudia and Beltran Velez, Nicolas and Nazaret, Achille and Zheng, Carolina and Garriga-Alonso, Adri{\`a} and Jesson, Andrew and Makar, Maggie and Blei, David},
  journal      = {Advances in Neural Information Processing Systems},
  volume       = {37},
  pages        = {94539--94567},
  year         = {2024}
}
@inproceedings{perlis2017internal,
  title        = {The Internal Reasoning of Robots},
  author       = {Perlis, Don and Brody, Justin and Kraus, Sarit and Miller, Michael J},
  booktitle    = {COMMONSENSE},
  year         = {2017}
}
@article{ji2023survey,
  title        = {Survey of hallucination in natural language generation},
  author       = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Yejin and Dai, Andrea and Madotto, Andrea and others},
  journal      = {ACM Computing Surveys},
  year         = {2023},
  publisher    = {ACM New York, NY}
}

@article{bubeck2023sparks,
  title        = {Sparks of artificial general intelligence: Early experiments with GPT-4},
  author       = {Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal      = {arXiv preprint arXiv:2303.12712},
  year         = {2023}
}

@article{dziri2023faith,
  title        = {Faith and fate: Limits of transformers on compositionality},
  author       = {Dziri, Nouha and Yasunaga, Michihiro and Polu, Stanislas and Luan, Yi and Alberti, Chris and Berant, Jonathan and Petrov, Slav and Liang, Percy},
  journal      = {arXiv preprint arXiv:2305.18654},
  year         = {2023}
}

@article{peng2024instruction,
  title        = {Instruction-following techniques do not solve transformer function composition},
  author       = {Peng, Sarah and Garg, Siddhant and Zhou, Denny and Steinhardt, Jacob},
  journal      = {arXiv preprint arXiv:2404.05527},
  year         = {2024}
}

@misc{kavlakoglu2024chain,
  author       = {Eda Kavlakoglu},
  title        = {What is Chain of Thoughts (CoT)?},
  year         = {2024},
  howpublished = {IBM Research Blog},
  url          = {https://research.ibm.com/blog/what-is-chain-of-thought-prompting},
  note         = {Accessed on [Insert Date You Accessed]}
}

@misc{AppleResearch2024Limitations,
  author       = {Psychology Today},
  title        = {The Truth About LLMs and Their Evolving Capabilities},
  year         = {2024},
  month        = {October},
  howpublished = {Psychology Today},
  url          = {https://www.psychologytoday.com/us/blog/the-digital-self/202410/the-truth-about-llms-and-their-evolving-capabilities},
  note         = {Discussing research from Apple. Accessed on [Insert Date You Accessed]}
}

@misc{xu2025chain,
  title        = {Chain of Draft: Thinking Faster by Writing Less},
  author       = {Silei Xu and Wenhao Xie and Lingxiao Zhao and Pengcheng He},
  year         = {2025},
  eprint       = {2502.11807},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL}
}

@misc{widthAIReact2023,
  author       = {Width.ai},
  title        = {ReAct Prompting: How We Prompt for High-Quality Results from LLMs},
  year         = {2023},
  month        = {September},
  howpublished = {Width.ai Blog},
  url          = {https://width.ai/blog/react-prompting},
  note         = {Accessed on [Insert Date You Accessed]}
}

@misc{madaan2023self,
  title        = {Self-Refine: Iterative Refinement with Self-Feedback},
  author       = {Aman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and Sean Welleck and Bodhisattwa Prasad Majumder and Shashank Gupta and Amir Yazdanbakhsh and Peter Clark},
  year         = {2023},
  eprint       = {2303.17651},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL}
}

@article{nakaishi2024critical,
  title={Critical Phase Transition in Large Language Models},
  author={Nakaishi, Kai and Nishikawa, Yoshihiko and Hukushima, Koji},
  journal={arXiv preprint arXiv:2406.05335},
  year={2024}
}
@article{vafa2024large,
  title={Do large language models perform the way people expect? measuring the human generalization function},
  author={Vafa, Keyon and Rambachan, Ashesh and Mullainathan, Sendhil},
  journal={arXiv preprint arXiv:2406.01382},
  year={2024}
}

@article{CoconutLatentReasoning2024,
  title        = {Training Large Language Models to Reason in a Continuous Latent Space},
  author       = {Shen, Xuan and Wang, Yizhou and Shi, Xiangxi and Wang, Yanzhi and Zhao, Pu and Gu, Jiuxiang},
  journal      = {arXiv preprint arXiv:2412.07423},
  year         = {2024},
}

@misc{ShentuHierarchical2024,
  title        = {From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control},
  author       = {Yide Shentu and Akhil Raju and Norman Di Palo and Brijen Thananjeyan and Wareesa Ahmad and Nemanja Ćećez and Vidhi Jain and Homer Richert and Ayzaan Wahid and Joachim Valente and Ted Xiao and Quan Vuong and Jonathan Tompson and Sumeet Singh and Peng Xu and Kanishka Rao},
  year         = {2024},
  eprint       = {2406.03909},
  archivePrefix = {arXiv},
  primaryClass = {cs.RO},
  note         = {Discusses limitations of monolithic LLMs and proposes modular approach, see [1]}
}

@misc{ScientificReasoningLimits2025,
  title        = {Beyond Scaling Laws: Towards Scientific Reasoning-Driven LLM Architectures},
  author       = {Ishita Dasgupta and Federico Bianchi and Michael W. Mahoney},
  year         = {2025},
  eprint       = {2504.2088},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  note         = {Discusses architectural misalignment of current LLMs for scientific reasoning, implying monolithic limitations, see [5]}
}

@misc{SurveyReasoningScaling2025,
  title        = {A Survey of Scaling in Large Language Model Reasoning},
  author       = {Yifan Gong and Jielin Qiu and Jiacheng Liu and Qingqing Cao and Yujia Qin and Chao Qu and Jie Zhou and Ji Zhang and Yao Wan and Yue Zhang and Zhiyuan Liu and Maosong Sun},
  year         = {2025},
  eprint       = {2504.01066},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  note         = {Surveys techniques including latent-space reasoning and associated challenges, see [7]}
}

@article{badre2021cognitive,
  title        = {Cognitive control as an emergent property},
  author       = {Badre, David and Nee, Derek Evan},
  journal      = {Nature Reviews Neuroscience},
  volume       = {22},
  number       = {5},
  pages        = {301--313},
  year         = {2021},
  publisher    = {Nature Publishing Group}
}

@article{donoso2014modelbased,
  title        = {Model-based learning and the contribution of the prefrontal cortex to adaptive behavior},
  author       = {Donoso, Marios and Collins, Anne GE and Koechlin, Etienne},
  journal      = {Annals of the New York Academy of Sciences},
  volume       = {1339},
  number       = {1},
  pages        = {119--129},
  year         = {2014},
  publisher    = {Wiley Online Library}
}
@article{posani2025rarely,
  title={Rarely categorical, always high-dimensional: how the neural code changes along the cortical hierarchy},
  author={Posani, Lorenzo and Wang, Shuqi and Muscinelli, Samuel P and Paninski, Liam and Fusi, Stefano},
  journal={bioRxiv},
  pages={2024--11},
  year={2025}
}
@article{sporns2016modular,
  title        = {Modular brain networks},
  author       = {Sporns, Olaf and Betzel, Richard F},
  journal      = {Annual review of psychology},
  volume       = {67},
  pages        = {613--640},
  year         = {2016},
  publisher    = {Annual Reviews}
}
@article{fodor1985precis,
  title={Precis of the modularity of mind},
  author={Fodor, Jerry A},
  journal={Behavioral and brain sciences},
  volume={8},
  number={1},
  pages={1--5},
  year={1985},
  publisher={Cambridge University Press}
}
@article{baars2005global,
  title={Global workspace theory of consciousness: toward a cognitive neuroscience of human experience},
  author={Baars, Bernard J},
  journal={Progress in brain research},
  volume={150},
  pages={45--53},
  year={2005},
  publisher={Elsevier}
}
@article{tononi1998complexity,
  title={Complexity and coherency: integrating information in the brain},
  author={Tononi, Giulio and Edelman, Gerald M and Sporns, Olaf},
  journal={Trends in cognitive sciences},
  volume={2},
  number={12},
  pages={474--484},
  year={1998},
  publisher={Elsevier}
}
@article{fries2015rhythms,
  title        = {Rhythms for cognition: communication through coherence},
  author       = {Fries, Pascal},
  journal      = {Neuron},
  volume       = {88},
  number       = {1},
  pages        = {220--235},
  year         = {2015},
  publisher    = {Elsevier}
}
@article{dehaene2011experimental,
  title={Experimental and theoretical approaches to conscious processing},
  author={Dehaene, Stanislas and Changeux, Jean-Pierre},
  journal={Neuron},
  volume={70},
  number={2},
  pages={200--227},
  year={2011},
  publisher={Elsevier}
}
@article{siegel2012spectral,
  title        = {Spectral fingerprints of large-scale neuronal interactions},
  author       = {Siegel, Markus and Donner, Tobias H and Engel, Andreas K},
  journal      = {Nature Reviews Neuroscience},
  volume       = {13},
  number       = {2},
  pages        = {121--134},
  year         = {2012},
  publisher    = {Nature Publishing Group}
}

@article{logothetis1996visual,
  title        = {Visual object recognition},
  author       = {Logothetis, NK and Sheinberg, DL},
  journal      = {Annual review of neuroscience},
  volume       = {19},
  number       = {1},
  pages        = {577--621},
  year         = {1996},
  publisher    = {Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, CA 94303-0139, USA}
}

@article{fries2007gamma,
  title        = {The gamma cycle},
  author       = {Fries, Pascal and Nikoli{\'c}, Danko and Singer, Wolf},
  journal      = {Trends in neurosciences},
  volume       = {30},
  number       = {7},
  pages        = {309--316},
  year         = {2007},
  publisher    = {Elsevier}
}

@inproceedings{wang2023selfconsistency,
  title        = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author       = {Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc V Le and Ed H. Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
  booktitle    = {The Eleventh International Conference on Learning Representations },
  year         = {2023}
}

@misc{anthropic2024claude3,
  title        = {The Claude 3 Model Family: Opus, Sonnet, Haiku},
  author       = {{Anthropic}},
  year         = {2024},
  month        = {March},
  howpublished = {Anthropic News},
  url          = {https://www.anthropic.com/news/claude-3-family}
}

@article{team2023gemini,
  title        = {Gemini: A Family of Highly Capable Multimodal Models},
  author       = {{Gemini Team} and others},
  journal      = {arXiv preprint arXiv:2312.11805},
  year         = {2023}
}

@inproceedings{yao2023tree,
  title        = {Tree of thoughts: Deliberate problem solving with large language models},
  author       = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Sha, Izhak and Nikhil, Rao and Karthik, Narasimhan and Benjamin, Van Durme and Gholami, Behzad and Rajani, Nazneen},
  booktitle    = {Advances in Neural Information Processing Systems},
  year         = {2023}
}

@inproceedings{ouyang2022training,
  title        = {Training language models to follow instructions with human feedback},
  author       = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  booktitle    = {Advances in Neural Information Processing Systems},
  volume       = {35},
  pages        = {27730--27744},
  year         = {2022}
}

@article{bai2022constitutional,
  title        = {Constitutional AI: Harmlessness from AI Feedback},
  author       = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal      = {arXiv preprint arXiv:2212.08073},
  year         = {2022}
}

@article{askell2021general,
  title        = {A General Language Assistant as a Laboratory for Alignment},
  author       = {Askell, Amanda and Bai, Yuntao and Chen, Anna and Dosovitskiy, Alexey and Drain, Dawn and Ganguli, Deep and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Kapturowski, S{\l}awomir and others},
  journal      = {arXiv preprint arXiv:2112.00861},
  year         = {2021}
}

@inproceedings{Geiping2024Latent,
  title        = {Latent Reasoning in Language Models},
  author       = {Geiping, Jonas and Prystawski, B{\l}a{\.z}ej and Bau, David and Goldstein, Tom},
  booktitle    = {International Conference on Learning Representations},
  year         = {2024}
}

@article{prystawski2023think,
  title        = {Why think step-by-step? Reasoning emerges from the locality of experience},
  author       = {Prystawski, B{\l}a{\.z}ej and Yiu, Enoch and Kruszewski, Germ{\'a}n and Liska, Martin and Yogatama, Dani and Kiela, Douwe and Cho, Kyunghyun and Testuggine, David},
  journal      = {arXiv preprint arXiv:2304.03843},
  year         = {2023}
}

@article{ullman2023large,
  title        = {Large language models fail on trivial alterations to theory-of-mind tasks},
  author       = {Ullman, Tomer},
  journal      = {arXiv preprint arXiv:2302.08396},
  year         = {2023}
}

@article{huang2023large,
  title        = {Large language models cannot reliably implement policies described in natural language},
  author       = {Huang, Jonathan K and Laskin, Michael and Liu, Tatsunori B and Abbeel, Pieter and Dragan, Anca D},
  journal      = {arXiv preprint arXiv:2311.01821},
  year         = {2023}
}

@inproceedings{bender2021dangers,
  title        = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  author       = {Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle    = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  pages        = {610--623},
  year         = {2021}
}

@article{pearl2023three,
  title        = {The Three C’s of AI: Causal, Counterfactual, and Contemplative},
  author       = {Pearl, Judea},
  journal      = {Daedalus},
  volume       = {152},
  number       = {4},
  pages        = {18--22},
  year         = {2023}
}

@article{hoffmann2022training,
  title        = {Training compute-optimal large language models},
  author       = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal      = {arXiv preprint arXiv:2203.15556},
  year         = {2022}
}

@book{marcus2022rebooting,
  title        = {Rebooting AI: Building artificial intelligence we can trust},
  author       = {Marcus, Gary and Davis, Ernest},
  year         = {2019},
  publisher    = {Pantheon Books}
}

@article{linzen2023can,
  title        = {Can large language models be good cognitive models of human sentence processing?},
  author       = {Linzen, Tal and Baroni, Marco},
  journal      = {Trends in Cognitive Sciences},
  volume       = {27},
  number       = {6},
  pages        = {536--547},
  year         = {2023}
}

@article{zhang2023siren,
  title        = {Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models},
  author       = {Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Wang, Xinting and Chen, Enri and Zhao, Yao and Zhang, Yulong and others},
  journal      = {arXiv preprint arXiv:2309.01219},
  year         = {2023}
}

@article{rawte2023survey,
  title        = {A Survey of Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions},
  author       = {Rawte, Vipula and Sheth, Amit and Das, Amitava},
  journal      = {arXiv preprint arXiv:2311.05232},
  year         = {2023}
}

@article{webb2023emergent,
  title        = {Emergent analogical reasoning in large language models},
  author       = {Webb, Taylor and Holyoak, Keith J and Lu, Hongjing},
  journal      = {Nature Human Behaviour},
  volume       = {7},
  number       = {10},
  pages        = {1708--1716},
  year         = {2023}
}

@incollection{pinker2003language,
  title        = {Language as an adaptation to the cognitive niche},
  author       = {Pinker, Steven},
  booktitle    = {Language evolution},
  pages        = {16--37},
  year         = {2003},
  publisher    = {Oxford University Press}
}

@article{huth2016natural,
  title        = {Natural speech reveals the semantic maps that tile human cerebral cortex},
  author       = {Huth, Alexander G and De Heer, Wendy A and Griffiths, Thomas L and Theunissen, Fr{\'e}d{\'e}ric E and Gallant, Jack L},
  journal      = {Nature},
  volume       = {532},
  number       = {7600},
  pages        = {453--458},
  year         = {2016}
}

@article{duncan2010multiple,
  title={The multiple-demand (MD) system of the primate brain: mental programs for intelligent behaviour},
  author={Duncan, John},
  journal={Trends in cognitive sciences},
  volume={14},
  number={4},
  pages={172--179},
  year={2010},
  publisher={Elsevier}
}

@article{blank2024dissociating,
  title        = {Dissociating language and thought in large language models: a cognitive perspective},
  author       = {Blank, Idan A and Fedorenko, Evelina and Tenenbaum, Joshua B and Gibson, Edward},
  journal      = {Trends in Cognitive Sciences},
  year         = {2024},
  publisher    = {Elsevier}
}

@article{lake2023ai,
  title        = {AI and the Causal Arrow},
  author       = {Lake, Brenden M and Murphy, Gregory L and Tenenbaum, Joshua B},
  journal      = {Trends in Cognitive Sciences},
  volume       = {27},
  number       = {12},
  pages        = {1107--1109},
  year         = {2023}
}

@article{goyal2022inductive,
  title        = {Inductive biases for deep learning of higher-level cognition},
  author       = {Goyal, Anirudh and Bengio, Yoshua},
  journal      = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume       = {478},
  number       = {2266},
  pages        = {20210068},
  year         = {2022}
}

@article{mitchell2021ai,
  title        = {Why AI is harder than we think},
  author       = {Mitchell, Melanie},
  journal      = {arXiv preprint arXiv:2104.12871},
  year         = {2021}
}

@article{shinn2023reflexion,
  title        = {Reflexion: Language agents with verbal reinforcement learning},
  author       = {Shinn, Noah and Labash, Beck and Gopinath, Ashwin},
  journal      = {arXiv preprint arXiv:2303.11366},
  year         = {2023}
}

@article{kadavath2022language,
  title        = {Language models (mostly) know what they know},
  author       = {Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schuurmans, Dale and Joseph, Nicholas and Mann, Ben and Goldie, Anna and others},
  journal      = {arXiv preprint arXiv:2207.05221},
  year         = {2022}
}

@article{huang2024largeverify,
  title        = {Large Language Models as Verifiers},
  author       = {Huang, Jie and Gu, Simiao and Fei, Han and Zhao, Ziyu and Yu, Jeffrey Xu and Chang, Kwang-Ting},
  journal      = {arXiv preprint arXiv:2402.09381},
  year         = {2024}
}

@article{sui2025stop,
  title={Stop overthinking: A survey on efficient reasoning for large language models},
  author={Sui, Yang and Chuang, Yu-Neng and Wang, Guanchu and Zhang, Jiamu and Zhang, Tianyi and Yuan, Jiayi and Liu, Hongyi and Wen, Andrew and Zhong, Shaochen and Chen, Hanjie and others},
  journal={arXiv preprint arXiv:2503.16419},
  year={2025}
}

@article{valmeekam2023can,
  title        = {Can LLaMA Reason? A Review and Analysis of the Reasoning Abilities of Large Language Models},
  author       = {Valmeekam, Karthik and D’Souza, Sarath S and Sreedharan, Jithin K and Shaikh, Subbarao and Sikka, Hrishikesh and Soni, Atul and Kambhampati, Subbarao},
  journal      = {arXiv preprint arXiv:2310.08225},
  year         = {2023}
}

@article{turpin2023language,
  title        = {Language Models Don't Always Say What They Think: Uncovering Ccertainty Tthrough Sdecoding},
  author       = {Turpin, M and Michael, Julian and Perez, Ethan and Liska, Martin},
  journal      = {arXiv preprint arXiv:2305.15460},
  year         = {2023}
}

@article{chen2024transformers,
  title        = {Transformers are Expressive, But Can They Be Efficiently Trained?},
  author       = {Chen, Zixiang and Arjovsky, Martin and Bengio, Yoshua and Mroueh, Youssef and Tomczak, Jakub M and Poggio, Tomaso and Bach, Francis},
  journal      = {arXiv preprint arXiv:2402.04400},
  year         = {2024}
}

@article{lin2020limitations,
  title={Limitations of autoregressive models and their alternatives},
  author={Lin, Chu-Cheng and Jaech, Aaron and Li, Xin and Gormley, Matthew R and Eisner, Jason},
  journal={arXiv preprint arXiv:2010.11939},
  year={2020}
}

@article{deng2024explicit,
  title={From explicit cot to implicit cot: Learning to internalize cot step by step},
  author={Deng, Yuntian and Choi, Yejin and Shieber, Stuart},
  journal={arXiv preprint arXiv:2405.14838},
  year={2024}
}
@article{wang2024deepnet,
  title={Deepnet: Scaling transformers to 1,000 layers},
  author={Wang, Hongyu and Ma, Shuming and Dong, Li and Huang, Shaohan and Zhang, Dongdong and Wei, Furu},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@article{Chen2025AutoregressiveLimitations,
  title        = {The Bottlenecks of Autoregressive Models in Complex Reasoning Tasks},
  author       = {Chen, X. and Lee, Y. and Zhang, Q.},
  journal      = {Journal of Advanced AI Architectures (Hypothetical)},
  year         = {2025}
}

@article{park2023generative,
  title        = {Generative agents: Interactive simulacra of human behavior},
  author       = {Park, Joon Sung and O'Brien, Joseph C and Cai, Carrie J and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  journal      = {arXiv preprint arXiv:2304.03442},
  year         = {2023}
}

@misc{kim2023alphacode2,
  title        = {AlphaCode 2 Technical Report},
  author       = {Kim, J. and others},
  year         = {2023},
  howpublished = {Google DeepMind Blog},
  url          = {https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf}
}

@article{rusch2023think,
  title        = {Think before you speak: Why transformers are so good at language},
  author       = {R{\"u}sch, T Konstantin and Le, Jason d and Grohs, Philipp and Gitta, Kutyniok},
  journal      = {SIAM Review},
  volume       = {65},
  number       = {4},
  pages        = {1056--1104},
  year         = {2023}
}

@article{nye2021show,
  title        = {Show Your Work: Scratchpads for Intermediate Computation with Language Models},
  author       = {Nye, Maxwell I and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Le, Quoc V and Sutton, Charles and Dohan, David},
  journal      = {Transactions of the Association for Computational Linguistics},
  volume       = {10},
  pages        = {74--90},
  year         = {2022}
}

@article{lanham2023measuring,
  title        = {Measuring and Narrowing the Compositionality Gap in Language Models},
  author       = {Lanham, Ofir and Gupta, Ishita and Hudson, Taylor and Thickstun, John and Ryskina, Marianna and Ethayarajh, Kawin and Andreas, Jacob and Choi, Yoon Kim and Manning, Christopher D},
  journal      = {arXiv preprint arXiv:2305.10164},
  year         = {2023}
}

@article{yu2023limits,
  title        = {The limits of chain-of-thought reasoning in large language models},
  author       = {Yu, Aojun and Qian, Haotian and Liu, Sishuo and Ren, Hongming and Liu, Yike and Zhang, Yike and Deng, Zhiyuan and Wang, Beichen and Zhao, Tuo and Zhang, Chao},
  journal      = {arXiv preprint arXiv:2308.05773},
  year         = {2023}
}

@article{wu2023reasoning,
  title        = {Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks},
  author       = {Wu, Zhaofeng and Liu, Linmeng and Zhong, Wenyue and Yuan, Nianlong and Zhou, Jiacheng and Jiang, Tao and Li, Qing and Tay, Yong},
  journal      = {arXiv preprint arXiv:2307.02477},
  year         = {2023}
}

@article{bietti2023birth,
  title        = {The birth of a new physics: The limits of neural scaling},
  author       = {Bietti, Alberto and Bach, Francis},
  journal      = {arXiv preprint arXiv:2310.05275},
  year         = {2023}
}

@article{feng2024towards,
  title        = {Towards a Standardized and More Rigorous Evaluation of Reasoning in Large Language Models},
  author       = {Feng, Ruixin and Wang, Peiyi and Chen, Weiyan and Wang, Borong and Xie, Tianyu and Lin, Yequan and Liu, Chen},
  journal      = {arXiv preprint arXiv:2402.04320},
  year         = {2024}
}

@article{zheng2023progressivehint,
  title        = {Progressive-Hint Prompting Improves Reasoning in Large Language Models},
  author       = {Zheng, Chuanyang and Liu, Zhengying and Niu, Ennog and Saveta, Tingburi and Geng, Shuo and Ren, Boyuan and Zou, Huanshuai and Zhang, Jian},
  journal      = {arXiv preprint arXiv:2304.09797},
  year         = {2023}
}

@article{xiong2023examining,
  title        = {Examining the Causal Effects of Chain-of-Thought Reasoning on Large Language Models: An In-Depth Analysis},
  author       = {Xiong, Bo and Zhang, Yiran and Jin, Lifu},
  journal      = {arXiv preprint arXiv:2310.08357},
  year         = {2023}
}

@article{goyal2023coordinate,
  title        = {Coordinate to Reason: Learning to Use Tools for Multi-Step Reasoning},
  author       = {Goyal, Shweta and Zhang, Zequn and Arora, Sanchit and Kumar, Sreyas and Raghunathan, Aditi},
  journal      = {arXiv preprint arXiv:2305.15941},
  year         = {2023}
}

@article{lampinen2023symbolic,
  title        = {Symbolic AI and Deep Learning: A Loving Embrace or Irreconcilable Differences?},
  author       = {Lampinen, Andrew K},
  journal      = {arXiv preprint arXiv:2310.09130},
  year         = {2023}
}

@article{van2023cognitive,
  title        = {Cognitive Architectures for Language Agents},
  author       = {van der Velde, Frank and de Kock, Cokie and Forth, Jamie},
  journal      = {arXiv preprint arXiv:2309.02427},
  year         = {2023}
}

@article{graves2023understanding,
  title        = {Understanding the limits of transformers: The role of recurrence},
  author       = {Graves, Alex and Miconi, Thomas and Bellec, Guillaume and Wayne, Greg and Danihelka, Ivo},
  journal      = {arXiv preprint arXiv:2312.10694},
  year         = {2023}
}
@article{luo2023empirical,
  title={An empirical study of catastrophic forgetting in large language models during continual fine-tuning},
  author={Luo, Yun and Yang, Zhen and Meng, Fandong and Li, Yafu and Zhou, Jie and Zhang, Yue},
  journal={arXiv preprint arXiv:2308.08747},
  year={2023}
}

@book{fodor1983modularity,
  title        = {The modularity of mind},
  author       = {Fodor, Jerry A},
  year         = {1983},
  publisher    = {MIT press}
}
@article{luppi2024synergistic,
  title={A synergistic workspace for human consciousness revealed by integrated information decomposition},
  author={Luppi, Andrea I and Mediano, Pedro AM and Rosas, Fernando E and Allanson, Judith and Pickard, John and Carhart-Harris, Robin L and Williams, Guy B and Craig, Michael M and Finoia, Paola and Owen, Adrian M and others},
  journal={Elife},
  volume={12},
  pages={RP88173},
  year={2024},
  publisher={eLife Sciences Publications Limited}
}
@article{mesulam1998from,
  title        = {From sensation to cognition},
  author       = {Mesulam, M-Marsel},
  journal      = {Brain: a journal of neurology},
  volume       = {121},
  number       = {6},
  pages        = {1013--1052},
  year         = {1998}
}

@article{park2013structural,
  title        = {Structural and functional brain networks: from connections to cognition},
  author       = {Park, Hae-Jeong and Friston, Karl},
  journal      = {Science},
  volume       = {342},
  number       = {6158},
  pages        = {1238411},
  year         = {2013}
}

@article{koutini2023quest,
  title        = {On the Quest for Modularity in Deep Learning},
  author       = {Koutini, Khaled and Cakir, Emre and Masarczyk, Wojciech and Rame, Ayoub and Illium, Steffen and Schuller, Bj{\"o}rn W},
  journal      = {arXiv preprint arXiv:2305.16638},
  year         = {2023}
}

@article{bengio2023deep,
  title        = {Deep learning for AI},
  author       = {Bengio, Yoshua and LeCun, Yann and Hinton, Geoffrey},
  journal      = {Communications of the ACM},
  volume       = {64},
  number       = {7},
  pages        = {58--65},
  year         = {2021}
}

@article{marcus2023ai,
  title        = {AI's Jurassic Park moment},
  author       = {Marcus, Gary},
  journal      = {Communications of the ACM},
  volume       = {66},
  number       = {12},
  pages        = {21--24},
  year         = {2023}
}

@article{goyal2021recurrent,
  title        = {Recurrent independent mechanisms},
  author       = {Goyal, Anirudh and Lamb, Alex and Hoffmann, Jordan and Levine, Sergey and Bengio, Yoshua},
  journal      = {arXiv preprint arXiv:2103.00042},
  year         = {2021}
}

@article{havaei2023neuro,
  title        = {Neuro-inspired modular learning for lifelong adaptation},
  author       = {Havaei, Mohammad and Dutil, Francis and Bengio, Yoshua and Bacon, Pierre-Luc and Vazquez, David},
  journal      = {arXiv preprint arXiv:2307.06099},
  year         = {2023}
}

@article{liao2023learning,
  title        = {Learning to See the World in Panoptic Segments: A Neuro-Compositional Approach},
  author       = {Liao, Renell and Gkanatsios, Sparts and Hu, Kuan-Chieh and Pathak, Deepak and Andreas, Jacob},
  journal      = {arXiv preprint arXiv:2306.00983},
  year         = {2023}
}

@article{dasgupta2020neuro,
  title        = {A neuro-connectionist architecture for rapid, flexible, and generalizablecredit assignment},
  author       = {Dasgupta, Ishita and Schulz, Eric and Tenenbaum, Joshua B and Gershman, Samuel J},
  journal      = {bioRxiv},
  pages        = {2020--05},
  year         = {2020},
  publisher    = {Cold Spring Harbor Laboratory}
}

@article{wang2024metacognitive,
  title        = {Metacognitive Prompting Improves Understanding and Usage of Large Language Models},
  author       = {Wang, Yifan and Ji, Zhaozheng and Wang, Zhipeng and Yang, Yixuan and Gao, Zhaoxuan and Yao, Yinda and Hu, Wei and Yu, Yong and Yin, Ming},
  journal      = {arXiv preprint arXiv:2402.03659},
  year         = {2024}
}

@article{hamrick2023role,
  title        = {The role of mental simulation in human and artificial intelligence},
  author       = {Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Merzic, Haris and P{\'e}rez, Ferran A},
  journal      = {Trends in Cognitive Sciences},
  year         = {2023}
}

@article{bengio2019meta,
  title        = {Meta-learning for fast adaptation and generalization in HCl},
  author       = {Bengio, Yoshua},
  journal      = {ACM SIGCHI Bulletin},
  volume       = {51},
  number       = {2},
  pages        = {1--13},
  year         = {2019}
}

@article{gershman2021computational,
  title        = {Computational rationality: A converging paradigm for intelligence in brains, minds, and machines},
  author       = {Gershman, Samuel J and Horvitz, Eric J and Tenenbaum, Joshua B},
  journal      = {Science},
  volume       = {349},
  number       = {6245},
  pages        = {273--278},
  year         = {2015}
}

@article{hassabis2017neuroscience,
  title        = {Neuroscience-inspired artificial intelligence},
  author       = {Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},
  journal      = {Neuron},
  volume       = {95},
  number       = {2},
  pages        = {245--258},
  year         = {2017}
}

@article{kriegeskorte2022ai,
  title        = {AI-generated images are a new window into the human mind},
  author       = {Kriegeskorte, Nikolaus and Golan, Tal},
  journal      = {Nature Human Behaviour},
  volume       = {6},
  number       = {8},
  pages        = {1022--1023},
  year         = {2022}
}

@book{fuster2015prefrontal,
  title        = {The prefrontal cortex},
  author       = {Fuster, Joaquin M},
  year         = {2015},
  publisher    = {Academic press}
}

@article{kanwisher2010functional,
  title        = {Functional specificity in the human brain: a window into the functional architecture of the mind},
  author       = {Kanwisher, Nancy},
  journal      = {Proceedings of the National Academy of Sciences},
  volume       = {107},
  number       = {25},
  pages        = {11163--11170},
  year         = {2010}
}

@article{van2013network,
  title        = {Network-based prediction of human thrust},
  author       = {Van den Heuvel, Martijn P and Sporns, Olaf},
  journal      = {Trends in cognitive sciences},
  volume       = {17},
  number       = {12},
  pages        = {685--695},
  year         = {2013}
}

@article{huth2023hierarchical,
  title        = {Hierarchical structure in the human brain's semantic system is preserved from language to vision},
  author       = {Huth, Alexander G and G{\textschwa}nb{\textschwa}r, Ekin and Gallant, Jack L},
  journal      = {Nature Neuroscience},
  volume       = {26},
  number       = {6},
  pages        = {1066--1076},
  year         = {2023}
}

@article{douglas1995recurrent,
  title        = {Recurrent excitation in neocortical circuits},
  author       = {Douglas, Rodney J and Koch, Christof and Mahowald, Misha and Martin, Kevan AC and Suarez, Humbert H},
  journal      = {Science},
  volume       = {269},
  number       = {5226},
  pages        = {981--985},
  year         = {1995}
}

@article{wang2001synaptic,
  title        = {Synaptic reverberation underlying mnemonic persistent activity in prefrontal cortex neurons},
  author       = {Wang, Xiao-Jing},
  journal      = {Neuron},
  volume       = {31},
  number       = {1},
  pages        = {113--125},
  year         = {2001}
}

@book{buzsaki2006rhythms,
  title        = {Rhythms of the Brain},
  author       = {Buzs{\'a}ki, Gy{\"o}rgy},
  year         = {2006},
  publisher    = {Oxford university press}
}

@article{engel2001dynamic,
  title        = {Dynamic predictions: oscillations and synchrony in top-down processing},
  author       = {Engel, Andreas K and Fries, Pascal and Singer, Wolf},
  journal      = {Nature reviews neuroscience},
  volume       = {2},
  number       = {10},
  pages        = {704--716},
  year         = {2001}
}

@article{collins2014reasoning,
  title        = {Reasoning and relational integration in frontal cortex},
  author       = {Collins, Anne and Koechlin, Etienne},
  journal      = {Annual review of neuroscience},
  volume       = {37},
  pages        = {167--186},
  year         = {2014}
}

@article{miller2001executive,
  title        = {An integrative theory of prefrontal cortex function},
  author       = {Miller, Earl K and Cohen, Jonathan D},
  journal      = {Annual review of neuroscience},
  volume       = {24},
  number       = {1},
  pages        = {167--202},
  year         = {2001}
}

@article{koechlin2003architecture,
  title        = {The architecture of cognitive control in the human prefrontal cortex},
  author       = {Koechlin, Etienne and Ody, Corinne and Kouneiher, Fourse},
  journal      = {Science},
  volume       = {302},
  number       = {5648},
  pages        = {1181--1185},
  year         = {2003}
}

@article{shenhav2013anterior,
  title        = {The anterior cingulate cortex and reinforcement learning: a model of task control and effort-related adjustments},
  author       = {Shenhav, Amitai and Botvinick, Matthew M and Cohen, Jonathan D},
  journal      = {Annual review of neuroscience},
  volume       = {36},
  pages        = {217--240},
  year         = {2013}
}

@article{carter2000anterior,
  title        = {Anterior cingulate cortex, error detection, and the online monitoring of performance},
  author       = {Carter, Cameron S and Braver, Todd S and Barch, Deanna M and Botvinick, Matthew M and Noll, Douglas and Cohen, Jonathan D},
  journal      = {Science},
  volume       = {280},
  number       = {5364},
  pages        = {747--749},
  year         = {1998}
}

@article{Hudson2024GNMR,
  author       = {Hudson, Taylor and Andreas, Jacob},
  title        = {Grounded Neural Model Reprogramming},
  journal      = {arXiv preprint arXiv:2402.11906},
  year         = {2024}
}

@article{DeepSeekR1,
  title        = {DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author       = {{DeepSeek-AI}},
  year         = {2025},
  journal      = {arXiv preprint arXiv:2501.12948},
  eprint       = {2501.12948},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  doi          = {10.48550/arXiv.2501.12948},
  url          = {https://arxiv.org/abs/2501.12948}
}

@article{Patil2025AdvancingReasoning,
  title        = {Advancing Reasoning in Large Language Models: Promising Methods and Approaches},
  author       = {Patil, Avinash},
  year         = {2025},
  journal      = {arXiv preprint arXiv:2502.03671},
  eprint       = {2502.03671},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  doi          = {10.48550/arXiv.2502.03671},
  url          = {https://arxiv.org/abs/2502.03671},
  note         = {Comments: 9 Pages, 1 Figure, IEEE Format}
}

@inproceedings{vaswani2017attention,
  title        = {Attention is all you need},
  author       = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle    = {Advances in neural information processing systems},
  pages        = {5998--6008},
  year         = {2017}
}

@article{kaplan2020scaling,
  title        = {Scaling laws for neural language models},
  author       = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal      = {arXiv preprint arXiv:2001.08361},
  year         = {2020}
}

@article{feng2023towards,
  title        = {A Survey on Large Language Model based Autonomous Agents},
  author       = {Feng, Lei and Chen, Xu and Chang, Yafei and Lin, Zhi and Wang, Yifei and Zhang, Jindong and Wang, Haopeng and Yin, Hongxin and Dou, Dejing and Zhao, Wen},
  journal      = {arXiv preprint arXiv:2308.11432},
  year         = {2023}
}

@article{BresslerMenon2010,
  title        = {Large-scale brain networks in cognition: emerging methods and principles},
  author       = {Bressler, Steven L and Menon, Vinod},
  journal      = {Trends in cognitive sciences},
  volume       = {14},
  number       = {6},
  pages        = {277--290},
  year         = {2010}
}

@article{Meunieretal2010,
  title        = {Modular and hierarchically modular organization of brain networks},
  author       = {Meunier, David and Lambiotte, Renaud and Fornito, Alex and Ersche, Karen D and Bullmore, Edward T},
  journal      = {Frontiers in neuroscience},
  volume       = {4},
  pages        = {200},
  year         = {2010}
}

@techreport{anil2023palm,
  title        = {PaLM 2 Technical Report},
  author       = {Anil, Rohan and Andor, D{\'a}vid and Anton, Alex and Bai, Jason and Bakhtin, Anton and Bali, Arjun and Ballard, Lucas and Basu, Sutanu and Bayer, Justin and Borgeaud, Sebastian and others},
  institution  = {Google Research},
  year         = {2023}
}

@misc{ziegler2020,
      title={Fine-Tuning Language Models from Human Preferences}, 
      author={Daniel M. Ziegler and Nisan Stiennon and Jeffrey Wu and Tom B. Brown and Alec Radford and Dario Amodei and Paul Christiano and Geoffrey Irving},
      year={2020},
      eprint={1909.08593},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1909.08593}, 
}

@misc{limr2025,
      title={LIMR: Less is More for RL Scaling}, 
      author={Xuefeng Li and Haoyang Zou and Pengfei Liu},
      year={2025},
      eprint={2502.11886},
      archivePrefix={arXiv},
      primaryClass={cs.LG} 
}

@misc{lightr12025,
      title={Light-R1: Curriculum SFT, DPO and RL for Long COT from Scratch and Beyond}, 
      author={Liang Wen and Yunke Cai and Fenrui Xiao and Xin He and Qi An and Zhenyu Duan and Yimin Du and Junchen Liu and Lifu Tang and Xiaowei Lv and Haosheng Zou and Yongchao Deng and Shousheng Jia and Xiangzheng Zhang},
      year={2025},
      eprint={2503.10460},
      archivePrefix={arXiv},
      primaryClass={cs.CL} 
}
@article{giadikiaroglou2024puzzle,
  title={Puzzle solving using reasoning of large language models: A survey},
  author={Giadikiaroglou, Panagiotis and Lymperaiou, Maria and Filandrianos, Giorgos and Stamou, Giorgos},
  journal={arXiv preprint arXiv:2402.11291},
  year={2024}
}
@inproceedings{helwe2021reasoning,
  title={Reasoning with transformer-based models: Deep learning, but shallow reasoning},
  author={Helwe, Chadi and Clavel, Chlo{\'e} and Suchanek, Fabian},
  booktitle={International Conference on Automated Knowledge Base Construction (AKBC)},
  year={2021}
}

@misc{wang2025,
      title={Reinforcement Learning for Reasoning in Large Language Models with One Training Example}, 
      author={Yiping Wang and Qing Yang and Zhiyuan Zeng and Liliang Ren and Lucas Liu and Baolin Peng and Hao Cheng and Xuehai He and Kuan Wang and Jianfeng Gao and Weizhu Chen and Shuohang Wang and Simon Shaolei Du and Yelong Shen},
      year={2025},
      eprint={2504.20571},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2504.20571}, 
}

@inproceedings{Bai2021StabilizingEM,
  title={Stabilizing Equilibrium Models by Jacobian Regularization},
  author={Shaojie Bai and Vladlen Koltun and J. Zico Kolter},
  booktitle={International Conference on Machine Learning},
  year={2021}
}

@INPROCEEDINGS {DEQ-Flow,
author = { Bai, Shaojie and Geng, Zhengyang and Savani, Yash and Kolter, J. Zico },
booktitle = { 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
title = {{ Deep Equilibrium Optical Flow Estimation }},
year = {2022},
pages = {610-620}
}


@InProceedings{Lee-DSN-2015,
  title = 	 {{Deeply-Supervised Nets}},
  author = 	 {Lee, Chen-Yu and Xie, Saining and Gallagher, Patrick and Zhang, Zhengyou and Tu, Zhuowen},
  booktitle = 	 {Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {562--570},
  year = 	 {2015}
}
@article{chen2025towards,
  title={Towards reasoning era: A survey of long chain-of-thought for reasoning large language models},
  author={Chen, Qiguang and Qin, Libo and Liu, Jinhao and Peng, Dengyun and Guan, Jiannan and Wang, Peng and Hu, Mengkang and Zhou, Yuhang and Gao, Te and Che, Wanxiang},
  journal={arXiv preprint arXiv:2503.09567},
  year={2025}
}

@misc{geiping2025,
      title={Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach}, 
      author={Jonas Geiping and Sean McLeish and Neel Jain and John Kirchenbauer and Siddharth Singh and Brian R. Bartoldson and Bhavya Kailkhura and Abhinav Bhatele and Tom Goldstein},
      year={2025},
      eprint={2502.05171},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@inproceedings{searchformer2024,
title={Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping},
author={Lucas Lehnert and Sainbayar Sukhbaatar and DiJia Su and Qinqing Zheng and Paul McVay and Michael Rabbat and Yuandong Tian},
booktitle={First Conference on Language Modeling},
year={2024}
}

@inproceedings{DLTM-2022,
title={Learning Iterative Reasoning through Energy Minimization},
author={Yilun Du and Shuang Li and Joshua Tenenbaum and Igor Mordatch},
booktitle={International Conference on Machine Learning},
year={2022}
}

@misc{dualformer2025,
      title={Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces}, 
      author={DiJia Su and Sainbayar Sukhbaatar and Michael Rabbat and Yuandong Tian and Qinqing Zheng},
      year={2025},
      eprint={2410.09918},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{PQN2025,
      title={Simplifying Deep Temporal Difference Learning}, 
      author={Matteo Gallici and Mattie Fellows and Benjamin Ellis and Bartomeu Pou and Ivan Masmitja and Jakob Nicolaus Foerster and Mario Martin},
      year={2025},
      eprint={2407.04811},
      archivePrefix={arXiv},
      primaryClass={cs.LG} 
}

@inproceedings{DMT-2024,
  author={Yilun Du and Jiayuan Mao and Joshua B. Tenenbaum},
  title={Learning Iterative Reasoning through Energy Diffusion},
  year={2024},
  booktitle={ICML}
}

@article{SHLPBL-2024,
title = {RoFormer: Enhanced transformer with Rotary Position Embedding},
journal = {Neurocomputing},
volume = {568},
pages = {127063},
year = {2024},
author = {Jianlin Su and Murtadha Ahmed and Yu Lu and Shengfeng Pan and Wen Bo and Yunfeng Liu}
}

@inproceedings{PBMB-2025,
title={Grokking at the Edge of Numerical Stability},
author={Lucas Prieto and Melih Barsbey and Pedro A. M. Mediano and Tolga Birdal},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025}
}

@inproceedings{EXWANLGSKLP-2024,
title={Scaling Exponents Across Parameterizations and Optimizers},
author={Katie E Everett and Lechao Xiao and Mitchell Wortsman and Alexander A Alemi and Roman Novak and Peter J Liu and Izzeddin Gur and Jascha Sohl-Dickstein and Leslie Pack Kaelbling and Jaehoon Lee and Jeffrey Pennington},
booktitle={Forty-first International Conference on Machine Learning},
year={2024}
}

@article{Anderson-1965,
title = {Iterative procedures for nonlinear integral equations},
journal = {Journal of the ACM (JACM)},
volume = {12},
pages = {547–560},
year = {1965},
author = {Donald G. Anderson}
}

@misc{KB-2017,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@book{Sutton-Barto-2018,
  title        = {Reinforcement Learning: An Introduction},
  author       = {Richard S. Sutton and Andrew G. Barto},
  publisher    = {MIT Press},
  year         = {2018},
  address      = {Cambridge, MA}
}

@book{Bach-2024,
  title        = {Learning Theory from First Principles},
  author       = {Francis Bach},
  publisher    = {MIT Press},
  year         = {2024},
  address      = {Cambridge, MA}
}

@book{HTF-2009,
  title        = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction.},
  author       = {Trevor Hastie and Robert Tibshirani and Jerome Friedman},
  publisher    = {Springer-Verlag},
  year         = {2009}
}

% Benchmarks - Maze
@article{Darlow2025ContinuousTM,
  title={Continuous thought machines},
  author={Darlow, Luke and Regan, Ciaran and Risi, Sebastian and Seely, Jeffrey and Jones, Llion},
  journal={arXiv preprint arXiv:2505.05522},
  year={2025}
}

% Benchmarks - ARC
@article{Chollet2025ARCAGI2AN,
  title={ARC-AGI-2: A New Challenge for Frontier AI Reasoning Systems},
  author={Chollet, Francois and Knoop, Mike and Kamradt, Gregory and Landers, Bryan and Pinkard, Henry},
  journal={arXiv preprint arXiv:2505.11831},
  year={2025}
}

@article{Chollet2024ARCP2,
  title={ARC Prize 2024: Technical Report},
  author={Francois Chollet and Mike Knoop and Gregory Kamradt and Bryan Landers},
  journal={ArXiv},
  year={2024},
  volume={abs/2412.04604}
}

@article{Dao2024TransformersAS,
  title={Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality},
  author={Tri Dao and Albert Gu},
  journal={ArXiv},
  year={2024},
  volume={abs/2405.21060}
}

@online{liao2025arcagiwithoutpretraining,
	author = {Isaac Liao and Albert Gu},
	title = {ARC-AGI Without Pretraining},
	year = {2025},
	url = {https://iliao2345.github.io/blog_posts/arc_agi_without_pretraining/arc_agi_without_pretraining.html},
}

@misc{arc24solutionsummary,
    url={https://ironbar.github.io/arc24/05_Solution_Summary}, journal={Solution Summary - arc24}
} 

% Benchmarks - Sudoku

@misc{tdoku,
  author       = {Tom Dillion},
  title        = {Tdoku: A Fast Sudoku Solver and Generator},
  howpublished = {\url{https://t-dillon.github.io/tdoku/}},
  year         = {2025}
}

@article{Du2024LearningIR,
  title={Learning Iterative Reasoning through Energy Diffusion},
  author={Yilun Du and Jiayuan Mao and Josh Tenenbaum},
  journal={ArXiv},
  year={2024},
  volume={abs/2406.11179}
}



@article{Long2023LargeLM,
  title={Large Language Model Guided Tree-of-Thought},
  author={Jieyi Long},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.08291}
}

@inproceedings{Palm2017RecurrentRN,
  title={Recurrent Relational Networks},
  author={Rasmus Berg Palm and Ulrich Paquet and Ole Winther},
  booktitle={Neural Information Processing Systems},
  year={2017}
}

@misc{sudoku2018,
  author = {Park, Kyubyong},
  title = {Can Convolutional Neural Networks Crack Sudoku Puzzles?},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/Kyubyong/sudoku}}
}

@misc{strobl-2023,
      title={Average-Hard Attention Transformers are Constant-Depth Uniform Threshold Circuits}, 
      author={Lena Strobl},
      year={2023},
      eprint={2308.03212},
      archivePrefix={arXiv},
      primaryClass={cs.CL} 
}

@article{Ivanitskiy2023ACL,
  title={A Configurable Library for Generating and Manipulating Maze Datasets},
  author={Michael I. Ivanitskiy and Rusheb Shah and Alex F Spies and Tilman Rauker and Dan Valentine and Can Rager and Lucia Quirke and Chris Mathwin and Guillaume Corlouer and Cecilia G. Diniz Behn and Samy Wu Fung Colorado School of Mines and Department of Applied Mathematics and Statistics Imperial College London},
  journal={ArXiv},
  year={2023},
  volume={abs/2309.10498}
}

@INPROCEEDINGS{wavefrontBFS,
  author={Kapadia, Mubbasir and Garcia, Francisco and Boatright, Cory D. and Badler, Norman I.},
  booktitle={2013 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Dynamic search on the GPU}, 
  year={2013},
  volume={},
  number={},
  pages={3332-3337},
  keywords={Graphics processing units;Heuristic algorithms;Kernel;Planning;Path planning;Navigation;Maintenance engineering},
  doi={10.1109/IROS.2013.6696830}}

@inproceedings{MS-2023,
  title={A logic for expressing log-precision transformers},
  author={William Merrill and Ashish Sabharwal},
  booktitle={Neural Information Processing Systems},
  year={2023}
}

@article{Villalobos2022WillWR,
  title={Will we run out of data? Limits of LLM scaling based on human-generated data},
  author={Villalobos, Pablo and Ho, Anson and Sevilla, Jaime and Besiroglu, Tamay and Heim, Lennart and Hobbhahn, Marius},
  journal={arXiv preprint arXiv:2211.04325},
  year={2022}
}

@article{Chiang-2025,
title = {Transformers in {DLOGTIME}-Uniform $\text{TC}^0$},
journal = {Transactions on Machine Learning Research},
year = {2025},
author = {David Chiang}
}

@article{Liu2023GoatFL,
  title={Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks},
  author={Tiedong Liu and Kian Hsiang Low},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.14201}
}

@inproceedings{Koutnk2014ACR,
  title={A Clockwork RNN},
  author={Jan Koutn{\'i}k and Klaus Greff and Faustino J. Gomez and J{\"u}rgen Schmidhuber},
  booktitle={International Conference on Machine Learning},
  year={2014}
}

@inproceedings{NIPS1995_c667d53a,
 author = {Hihi, Salah and Bengio, Yoshua},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Touretzky and M.C. Mozer and M. Hasselmo},
 pages = {},
 publisher = {MIT Press},
 title = {Hierarchical Recurrent Neural Networks for Long-Term Dependencies},
 volume = {8},
 year = {1995}
}

@article{Banino2021PonderNetLT,
  title={PonderNet: Learning to Ponder},
  author={Andrea Banino and Jan Balaguer and Charles Blundell},
  journal={ArXiv},
  year={2021},
  volume={abs/2107.05407}
}

@article{Graves2016AdaptiveCT,
  title={Adaptive Computation Time for Recurrent Neural Networks},
  author={Alex Graves},
  journal={ArXiv},
  year={2016},
  volume={abs/1603.08983}
}

@inproceedings{MS-2024,
  title={THE EXPRESSIVE POWER OF TRANSFORMERS WITH CHAIN OF THOUGHT},
  author={William Merrill and Ashish Sabharwal},
  booktitle={ICLR},
  year={2024}
}

@article{Bounsi2024TransformersMN,
  title={Transformers meet Neural Algorithmic Reasoners},
  author={Wilfried Bounsi and Borja Ibarz and Andrew Dudzik and Jessica B. Hamrick and Larisa Markeeva and Alex Vitvitskyi and Razvan Pascanu and Petar Velivckovi'c},
  journal={ArXiv},
  year={2024},
  volume={abs/2406.09308}
}

@inproceedings{
Lehnert2024BeyondAB,
title={Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping},
author={Lucas Lehnert and Sainbayar Sukhbaatar and DiJia Su and Qinqing Zheng and Paul McVay and Michael Rabbat and Yuandong Tian},
booktitle={First Conference on Language Modeling},
year={2024}}

@article{LILLICRAP201982,
title = {Backpropagation through time and the brain},
journal = {Current Opinion in Neurobiology},
volume = {55},
pages = {82-89},
year = {2019},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2019.01.011},
author = {Timothy P Lillicrap and Adam Santoro},
}

@article{Hopfield-1982,
author = {J J Hopfield },
title = {Neural networks and physical systems with emergent collective computational abilities.},
journal = {Proceedings of the National Academy of Sciences},
volume = {79},
number = {8},
pages = {2554-2558},
year = {1982}
}

@techreport{RHW-1985,
  title        = {Learning internal representations by error propagation},
  author       = {Rumelhart, David E; Hinton, Geoffrey E, and Williams, Ronald J},
  institution  = {San Diego, California: Institute for Cognitive Science, University of California},
  year         = {1985}
}

@techreport{Jordan-1986,
  title        = {Serial order: a parallel distributed processing approach},
  author       = {Jordan, Michael I.},
  institution  = {San Diego, California: Institute for Cognitive Science, University of California},
  year         = {1986}
}

@article{SS-1995,
author = {Hava Siegelmann and Eduardo Sontag},
title = {On the computational power of neural networks},
journal = {Journal of Computer and System Sciences},
pages = {132-150},
year = {1995}
}


@techreport{Mercury-2025,
  title        = {Mercury: Ultra-Fast Language Models Based on Diffusion},
  author       = {Inception Labs},
  institution  = {Inception Labs},
  year         = {2025}
}

@article{lcm2024,
  author = {{LCM team}, Lo\"{i}c Barrault, Paul-Ambroise Duquenne, Maha Elbayad, Artyom Kozhevnikov, Belen Alastruey, Pierre Andrews, Mariano Coria, Guillaume Couairon, Marta R. Costa-juss\`{a}, David Dale, Hady Elsahar, Kevin Heffernan, Jo\~{a}o Maria Janeiro, Tuan Tran, Christophe Ropers, Eduardo Sánchez, Robin San Roman, Alexandre Mourachko, Safiyyah Saleem, Holger Schwenk},
  title = {{Large Concept Models}: Language Modeling in a Sentence Representation Space},
  publisher = {arXiv},
  year = {2024}
}

@misc{SDT-Sudoku,
  title = {Single-digit techniques},
  howpublished = {\url{https://hodoku.sourceforge.net/en/tech_singles.php}},
  note = {Accessed: 2025-06-16}
}

@article{HHMM-1998,
  title={The hierarchical hidden Markov model: Analysis and applications},
  author={Fine, Shai and Singer, Yoram and Tishby, Naftali},
  journal={Machine learning},
  volume={32},
  number={1},
  pages={41--62},
  year={1998},
  publisher={Springer}
}

@article{SUTTON1999,
title = {Between {MDP}s and semi-{MDP}s: A framework for temporal abstraction in reinforcement learning},
journal = {Artificial Intelligence},
volume = {112},
number = {1},
pages = {181-211},
year = {1999},
author = {Richard S. Sutton and Doina Precup and Satinder Singh}
}

@article{BM-2003,
title = {Recent Advances in Hierarchical Reinforcement Learning},
journal = {Discrete Event Dynamic Systems},
volume = {13},
pages = {341–379},
year = {2003},
author = {A.G. Barto and S. Mahadevan}
}

@book{Minsky-1986,
  title={Society of Mind},
  author={Marvin Minsky},
  year={1986},
  publisher={Simon & Schuster}
}

@article{SOAR-1987,
title = {SOAR: An architecture for general intelligence},
journal = {Artificial Intelligence},
volume = {33},
number = {1},
pages = {1-64},
year = {1987},
author = {John E. Laird and Allen Newell and Paul S. Rosenbloom}
}

@misc{graves-ACT-2017,
      title={Adaptive Computation Time for Recurrent Neural Networks}, 
      author={Alex Graves},
      year={2017},
      eprint={1603.08983},
      archivePrefix={arXiv}
}


@article{wason1974dual,
  title={Dual processes in reasoning?},
  author={Wason, Peter C and Evans, J St BT},
  journal={Cognition},
  volume={3},
  number={2},
  pages={141--154},
  year={1974},
  publisher={Elsevier}
}

@article{wallis2001single,
  title={Single neurons in prefrontal cortex encode abstract rules},
  author={Wallis, Jonathan D and Anderson, Kathleen C and Miller, Earl K},
  journal={Nature},
  volume={411},
  number={6840},
  pages={953--956},
  year={2001},
  publisher={Nature Publishing Group UK London}
}

@article{friedman2022role,
  title={The role of prefrontal cortex in cognitive control and executive function},
  author={Friedman, Naomi P and Robbins, Trevor W},
  journal={Neuropsychopharmacology},
  volume={47},
  number={1},
  pages={72--89},
  year={2022},
  publisher={Springer International Publishing Cham}
}

@article{modirrousta2008medial,
  title={Medial prefrontal cortex plays a critical and selective role in ‘feeling of knowing’meta-memory judgments},
  author={Modirrousta, Mandana and Fellows, Lesley K},
  journal={Neuropsychologia},
  volume={46},
  number={12},
  pages={2958--2965},
  year={2008},
  publisher={Elsevier}
}


@article{cavanagh2014frontal,
  title={Frontal theta as a mechanism for cognitive control},
  author={Cavanagh, James F and Frank, Michael J},
  journal={Trends in cognitive sciences},
  volume={18},
  number={8},
  pages={414--421},
  year={2014},
  publisher={Elsevier}
}

@article{dumontheil2014development,
  title={Development of abstract thinking during childhood and adolescence: The role of rostrolateral prefrontal cortex},
  author={Dumontheil, Iroise},
  journal={Developmental cognitive neuroscience},
  volume={10},
  pages={57--76},
  year={2014},
  publisher={Elsevier}
}


@article{papyan2020prevalence,
  title        = {Prevalence of Neural Collapse during the Terminal Phase of Deep Learning Training},
  author       = {Papyan, Vardan and Han, X.~Y. and Donoho, David~L.},
  journal      = {Proceedings of the National Academy of Sciences},
  volume       = {117},
  number       = {40},
  pages        = {24652--24663},
  year         = {2020},
  publisher    = {National Academy of Sciences},
  doi          = {10.1073/pnas.2015509117}
}

@article{fang2021layerpeeled,
  title        = {Exploring Deep Neural Networks via Layer{\textendash}Peeled Model: Minority Collapse in Imbalanced Training},
  author       = {Fang, Cong and He, Hangfeng and Long, Qi and Su, Weijie~J.},
  journal      = {Proceedings of the National Academy of Sciences},
  volume       = {118},
  number       = {43},
  pages        = {e2103091118},
  year         = {2021},
  publisher    = {National Academy of Sciences},
  doi          = {10.1073/pnas.2103091118}
}

@inproceedings{zhu2021geometric,
  title        = {A Geometric Analysis of Neural Collapse with Unconstrained Features},
  author       = {Zhu, Zhihui and Ding, Tianyu and Zhou, Jinxin and Li, Xiao and You, Chong and Sulam, Jeremias and Qu, Qing},
  booktitle    = {Advances in Neural Information Processing Systems},
  series       = {NeurIPS},
  volume       = {34},
  pages        = {29820--29834},
  year         = {2021}
}

@inproceedings{zhou2022losses,
  title        = {Are All Losses Created Equal: A Neural Collapse Perspective},
  author       = {Zhou, Jinxin and You, Chong and Li, Xiao and Liu, Kangning and Liu, Sheng and Qu, Qing and Zhu, Zhihui},
  booktitle    = {Advances in Neural Information Processing Systems},
  series       = {NeurIPS},
  volume       = {35},
  pages        = {31697--31710},
  year         = {2022}
}

@inproceedings{sukenik2023deepnc,
  title        = {Deep Neural Collapse Is Provably Optimal for the Deep Unconstrained Features Model},
  author       = {S{\'u}ken{\'\i}k, Peter and Mondelli, Marco and Lampert, Christoph~H.},
  booktitle    = {Advances in Neural Information Processing Systems},
  series       = {NeurIPS},
  volume       = {36},
  year         = {2023},
  doi          = {10.48550/arXiv.2305.13165}
}

@article{rigotti2013importance,
  title     = {The importance of mixed selectivity in complex cognitive tasks},
  author    = {Rigotti, Mattia and Barak, Omri and Warden, Melissa R. and Wang, Xiao-Jing and Daw, Nathaniel D. and Miller, Earl K. and Fusi, Stefano},
  journal   = {Nature},
  volume    = {497},
  pages     = {585--590},
  year      = {2013},
  doi       = {10.1038/nature12160}
}

@article{altan2021estimating,
  title   = {Estimating the dimensionality of the manifold underlying multi-electrode neural recordings},
  author  = {Altan, Ege and Solla, Sara A. and Miller, Lee E. and Perreault, Eric J.},
  journal = {PLoS Computational Biology},
  volume  = {17},
  number  = {11},
  pages   = {e1008591},
  year    = {2021},
  doi     = {10.1371/journal.pcbi.1008591}
}

@article{maass2002realtime,
  title     = {Real-time computing without stable states: a new framework for neural computation based on perturbations},
  author    = {Maass, Wolfgang},
  journal   = {Neural Computation},
  volume    = {14},
  number    = {11},
  pages     = {2531--2560},
  year      = {2002},
  doi       = {10.1162/089976602760407955}
}

@article{miller2001integrative,
  title     = {An integrative theory of prefrontal cortex function},
  author    = {Miller, Earl K. and Cohen, Jonathan D.},
  journal   = {Annual Review of Neuroscience},
  volume    = {24},
  number    = {1},
  pages     = {167--202},
  year      = {2001},
  doi       = {10.1146/annurev.neuro.24.1.167}
}

@article{mante2013context,
  title     = {Context-dependent computation by recurrent dynamics in prefrontal cortex},
  author    = {Mante, Valerio and Sussillo, David and Shenoy, Krishna V. and Newsome, William T.},
  journal   = {Nature},
  volume    = {503},
  number    = {7474},
  pages     = {78--84},
  year      = {2013},
  doi       = {10.1038/nature12742}
}

@misc{NTK2014,
      title={Neural Turing Machines}, 
      author={Alex Graves and Greg Wayne and Ivo Danihelka},
      year={2014},
      eprint={1410.5401},
      archivePrefix={arXiv}
}
@article{DNC2016,
  title={Hybrid computing using a neural network with dynamic external memory},
  author={Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\'n}ska, Agnieszka and Colmenarejo, Sergio G{\'o}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and others},
  journal={Nature},
  volume={538},
  number={7626},
  pages={471--476},
  year={2016},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{KS-2016,
  title        = {Neural {GPU}s learn algorithms},
  author       = {Lukasz Kaiser and Ilya Sutskever},
  booktitle    = {ICLR},
  year         = {2016}
}